{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn, optim, cuda\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, \\\n",
    "                             TensorDataset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/bal31/jhsu/home/git/tmp/RENET2_b1/src/renet2/raw_handler.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm|\n",
    "\n",
    "from renet2.raw import load_documents\n",
    "from renet2.raw_handler import *\n",
    "from renet2.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renet2.train_renet2_ft_cv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n",
      "loading word index from /autofs/bal31/jhsu/home/git/tmp/RENET2_b1/src/renet2/utils/word_index\n",
      "loaded word index, voc size 82948\n",
      "tokenizer size 82949\n",
      "fix input sentences# 32, tokens# 54, batch size 32\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # set up\n",
    "    parser = init_self_parser()\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    sys.path.insert(0, 'renet2')\n",
    "    get_index_path(args)\n",
    "    \n",
    "    \n",
    "    use_cuda = torch.cuda.is_available() and not args.no_cuda\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "#     device = torch.device('cuda:1')\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    set_seed(args)\n",
    "    args.device = device\n",
    "    print('using device', device)\n",
    "\n",
    "    args.ori_tokenizer = loading_tokenizer(args)\n",
    "    args.token_voc_l = len(args.ori_tokenizer)\n",
    "    print('tokenizer size %d' % (args.token_voc_l))\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.fix_snt_n, args.fix_token_n = 32, 54   \n",
    "    \n",
    "    print('fix input sentences# %d, tokens# %d, batch size %d' % (args.fix_snt_n, args.fix_token_n, args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.overwrite_cache = False\n",
    "args.file_name_snt = \"sentences.txt\"\n",
    "args.file_name_ann = \"anns.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important specific the data dir\n",
    "# \"../../_data/data/abs_data/1st_ann/\"\n",
    "args.raw_data_dir = \"../../_data/data/abs_data/1st_ann/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cached file ../../_data/data/abs_data/1st_ann/cached_all_doc_0_32_54\n",
      "creating features from dataset file at  ../../_data/data/abs_data/1st_ann/\n",
      "reading files docs.txt,sentences.txt,anns.txt,labels.txt\n",
      "load data in path ../../_data/data/abs_data/1st_ann/docs.txt\n",
      "*** Example ***                      \n",
      "unique_id: 10234502\n",
      "pairs 14 doc snt num 19\n",
      "token string: [12] novel (['<5728>'], ['PTEN']) mutations in patients with (['<D006223>'], ['Cowden', 'disease']) absence of clear genotype-phenotype correlations\n",
      "token ids   : [12] 170 1344 28 4 10 5 2692 689 2 1496 1273 1251\n",
      "fix feature : [12] 0 5 0 0 0 0 4 0 0 0 0 0\n",
      "token string: [11] (['<D006223>'], ['Cowden', 'disease']) cd is characterised by (['<D006223>'], ['multiple', 'hamartomas']) in a variety of tissues\n",
      "token ids   : [11] 2692 8260 16 2779 21 2692 4 6 1646 2 750\n",
      "fix feature : [11] 4 0 0 0 0 4 0 0 0 0 0\n",
      "*** Example ***                      \n",
      "unique_id: 10506726\n",
      "pairs 2 doc snt num 13\n",
      "token string: [14] (['<2056>'], ['Erythropoietin']) reduces (['<D000740>'], ['anemia']) and transfusions a randomized trial with or without (['<2056>'], ['erythropoietin']) during chemotherapy\n",
      "token ids   : [14] 1847 2295 1822 3 9558 6 2227 1128 5 15 203 1847 300 658\n",
      "fix feature : [14] 5 0 4 0 0 0 0 0 0 0 0 5 0 0\n",
      "token string: [14] background (['<D000740>'], ['Anemia']) has been reported to develop during preoperative chemotherapy with paclitaxel and carboplatin\n",
      "token ids   : [14] 132 1822 87 55 171 7 849 300 7604 658 5 3567 3 6223\n",
      "fix feature : [14] 0 4 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "read 500 doc, max token len 0 40\n",
      "\n",
      "reading label at ../../_data/data/abs_data/1st_ann/labels.txt\n",
      "loaded document #  2813 2813 2813\n",
      "padding document with fix length 32 54\n",
      "total doc # 2813, reach end # 0 (0.00%)\n",
      "total snt # 90016, reach end # 312 (0.35%)\n",
      "total token # 4860864, not empty # 659825 valid rate: 13.57%\n",
      "saving features into cached file  ../../_data/data/abs_data/1st_ann/cached_all_doc_0_32_54\n",
      "loading ended\n"
     ]
    }
   ],
   "source": [
    "# args.raw_data_dir = \"../data/abs_data/1st_ann/\"\n",
    "args.label_f_name = \"labels.txt\"\n",
    "    \n",
    "features_ann_1 = load_and_cache_data(args)\n",
    "\n",
    "dataset_ann_1, _, _ = convert_features_to_dataset_single(features_ann_1)\n",
    "dataloader_ann_1 = DataLoader(dataset_ann_1, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cached file ../../_data/data/abs_data/2nd_ann/cached_all_doc_0_32_54\n",
      "creating features from dataset file at  ../../_data/data/abs_data/2nd_ann/\n",
      "reading files docs.txt,sentences.txt,anns.txt,labels.txt\n",
      "load data in path ../../_data/data/abs_data/2nd_ann/docs.txt\n",
      "*** Example ***                      \n",
      "unique_id: 10487688\n",
      "pairs 12 doc snt num 10\n",
      "token string: [20] differences in allelic distribution of two polymorphisms in the (['<7428>'], ['VHL']) -associated gene (['<8453>'], ['CUL2']) in (['<D010673>'], ['pheochromocytoma']) patients without somatic (['<8453>'], ['CUL2']) mutations\n",
      "token ids   : [20] 186 4 333 258 2 58 23 4 1 9798 7309 12 10207 4 4783 10 203 1035 10207 28\n",
      "fix feature : [20] 0 0 0 0 0 0 0 0 0 5 0 0 2 0 4 0 0 0 2 0\n",
      "token string: [32] although the two major familial forms of (['<D010673>'], ['pheochromocytomas']) (['<D018813>'], ['multiple', 'endocrine', 'neoplasia', 'type', '2']) and (['<D006623>'], ['von-Hippel-Lindau', 'disease']) (['<7428>'], ['VHL']) have been associated with mutations of the (['<5979>'], ['RET']) and (['<7428>'], ['VHL']) genes respectively the molecular pathogenesis of (['<D010673>'], ['sporadic', 'pheochromocytomas']) is largely unknown\n",
      "token ids   : [32] 264 1 58 270 603 805 2 4783 11280 3 5771 9798 48 55 20 5 28 2 1 1778 3 9798 34 109 1 299 290 2 4783 16 1864 642\n",
      "fix feature : [32] 0 0 0 0 0 0 0 4 1 0 1 5 0 0 0 0 0 0 0 2 0 5 0 0 0 0 0 0 4 0 0 0\n",
      "*** Example ***                      \n",
      "unique_id: 10545596\n",
      "pairs 2 doc snt num 11\n",
      "token string: [18] expression analysis of four (['<2022>'], ['endoglin']) missense mutations suggests that (['<D058495>'], ['haploinsufficiency']) is the predominant mechanism for (['<D013683>'], ['hereditary', 'hemorrhagic', 'telangiectasia']) type 1\n",
      "token ids   : [18] 72 49 2 228 4596 315 28 413 14 4526 16 1 2634 644 9 5317 246 89\n",
      "fix feature : [18] 0 0 0 0 5 0 0 0 0 4 0 0 0 0 0 1 0 0\n",
      "token string: [27] (['<2022>'], ['ENDOGLIN']) codes for a homodimeric membrane glycoprotein that interacts with receptors for members of the tgf-beta superfamily and is the gene mutated in the (['<D013683>'], ['autosomal', 'dominant', 'vascular', 'disorder', 'hereditary', 'hemorrhagic', 'telangiectasia', 'type']) 1 hht1\n",
      "token ids   : [27] 4596 4276 9 6 26687 1367 3561 14 3588 5 537 9 771 2 1 6763 3603 3 16 1 12 735 4 1 5317 89 13\n",
      "fix feature : [27] 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "read 500 doc, max token len 0 35\n",
      "\n",
      "reading label at ../../_data/data/abs_data/2nd_ann/labels.txt\n",
      "loaded document #  2734 2734 2734\n",
      "padding document with fix length 32 54\n",
      "total doc # 2734, reach end # 0 (0.00%)\n",
      "total snt # 87488, reach end # 334 (0.38%)\n",
      "total token # 4724352, not empty # 641701 valid rate: 13.58%\n",
      "saving features into cached file  ../../_data/data/abs_data/2nd_ann/cached_all_doc_0_32_54\n",
      "loading ended\n"
     ]
    }
   ],
   "source": [
    "args.raw_data_dir = \"../../_data/data/abs_data/2nd_ann/\"\n",
    "# args.raw_data_dir = \"../data/abs_data/2nd_ann/\"\n",
    "\n",
    "args.label_f_name = \"labels.txt\"\n",
    "    \n",
    "features_ss_aug = load_and_cache_data(args)\n",
    "\n",
    "dataset_ss_aug, _, _ = convert_features_to_dataset_single(features_ss_aug)\n",
    "dataloader_ss_aug = DataLoader(dataset_ss_aug, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_merge = np.concatenate((features_ann_1[0], features_ss_aug[0]), axis=0), \\\n",
    "                pd.concat([features_ann_1[1], features_ss_aug[1]])                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creading dataset, positive GDA 1858, all GDA 5547, positive rate 33.50%\n"
     ]
    }
   ],
   "source": [
    "dataset_merge, _, _ = convert_features_to_dataset_single(features_merge)\n",
    "dataloader_merge = DataLoader(dataset_merge, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512a675d7b1a406cb69265c702f80065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=88.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0.004669049611630317, 0.7086513994910941, 0.6402298850574712, 0.6727053140096618, 0.8448485870291822)\n"
     ]
    }
   ],
   "source": [
    "args.modle_dir = '../models/abs_models'\n",
    "model_name_prefix = 'DisGeNet_abs'\n",
    "checkpoint_f = os.path.join(args.modle_dir, model_name_prefix + \".ckp\")\n",
    "config_save_f = os.path.join(args.modle_dir,  model_name_prefix + \".cf\")\n",
    "\n",
    "config = torch.load(config_save_f)\n",
    "model, _, _ = load_checkpoint(config, checkpoint_f)\n",
    "\n",
    "config.device =  args.device\n",
    "\n",
    "args.is_iterare_info = False\n",
    "args.threshold = config.threshold \n",
    "args.l2_weight_decay = config.l2_weight_decay\n",
    "model.update_model_config(config)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "pred_l, tru_l, S, pred_o = eval(model, dataloader_ann_1, args, 'test')\n",
    "_, _, _, f1, auc = S\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00431, 0.7246, 0.5882, 0.6494, 0.8418]\n",
      "e_2 * test rst: [0.00424, 0.8088, 0.6471, 0.7190, 0.8548]\n",
      "e_3 * test rst: [0.00451, 0.8387, 0.6118, 0.7075, 0.8594]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00439, 0.6649, 0.7353, 0.6983, 0.8652]\n",
      "e_5 * test rst: [0.00461, 0.8468, 0.6176, 0.7143, 0.8604]\n",
      "e_6 * test rst: [0.00489, 0.6382, 0.7471, 0.6883, 0.8656]\n",
      "e_7 * test rst: [0.00478, 0.7296, 0.6824, 0.7052, 0.8631]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00476, 0.7262, 0.7176, 0.7219, 0.8613]\n",
      "e_9 * test rst: [0.00493, 0.7857, 0.6471, 0.7097, 0.8611]\n",
      "e_10 * test rst: [0.00475, 0.7135, 0.7176, 0.7155, 0.8648]\n",
      "e_11 * test rst: [0.00502, 0.6632, 0.7412, 0.7000, 0.8660]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00516, 0.6632, 0.7412, 0.7000, 0.8645]\n",
      "e_13 * test rst: [0.00501, 0.7052, 0.7176, 0.7114, 0.8638]\n",
      "e_14 * test rst: [0.00528, 0.6649, 0.7471, 0.7036, 0.8638]\n",
      "e_15 * test rst: [0.00499, 0.7052, 0.7176, 0.7114, 0.8635]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00506, 0.6954, 0.7118, 0.7035, 0.8634]\n",
      "e_17 * test rst: [0.00522, 0.6614, 0.7353, 0.6964, 0.8646]\n",
      "e_18 * test rst: [0.00516, 0.6796, 0.7235, 0.7009, 0.8645]\n",
      "training end, used 303.05 s\n",
      "(0.0051615752054785325, 0.6795580110497238, 0.7235294117647059, 0.7008547008547009, 0.8644514294267325)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00504, 0.8018, 0.5235, 0.6335, 0.8668]\n",
      "e_2 * test rst: [0.00466, 0.8300, 0.4882, 0.6148, 0.8780]\n",
      "e_3 * test rst: [0.00457, 0.6882, 0.6882, 0.6882, 0.8771]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00435, 0.6964, 0.6882, 0.6923, 0.8783]\n",
      "e_5 * test rst: [0.00467, 0.7450, 0.6529, 0.6959, 0.8831]\n",
      "e_6 * test rst: [0.00464, 0.6923, 0.6882, 0.6903, 0.8836]\n",
      "e_7 * test rst: [0.00475, 0.7290, 0.6647, 0.6954, 0.8878]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00480, 0.7233, 0.6765, 0.6991, 0.8884]\n",
      "e_9 * test rst: [0.00481, 0.6879, 0.7000, 0.6939, 0.8888]\n",
      "e_10 * test rst: [0.00488, 0.7205, 0.6824, 0.7009, 0.8904]\n",
      "e_11 * test rst: [0.00474, 0.6932, 0.7176, 0.7052, 0.8925]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00470, 0.7186, 0.7059, 0.7122, 0.8925]\n",
      "e_13 * test rst: [0.00476, 0.7069, 0.7235, 0.7151, 0.8943]\n",
      "e_14 * test rst: [0.00471, 0.7580, 0.7000, 0.7278, 0.8947]\n",
      "e_15 * test rst: [0.00467, 0.7628, 0.7000, 0.7301, 0.8944]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00471, 0.7516, 0.6941, 0.7217, 0.8942]\n",
      "e_17 * test rst: [0.00467, 0.7289, 0.7118, 0.7202, 0.8955]\n",
      "e_18 * test rst: [0.00476, 0.7186, 0.7059, 0.7122, 0.8947]\n",
      "training end, used 304.68 s\n",
      "(0.004759230689008325, 0.718562874251497, 0.7058823529411765, 0.712166172106825, 0.8947013920071847)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00562, 0.7760, 0.4949, 0.6044, 0.8318]\n",
      "e_2 * test rst: [0.00495, 0.6578, 0.7551, 0.7031, 0.8592]\n",
      "e_3 * test rst: [0.00472, 0.7472, 0.6786, 0.7112, 0.8613]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00472, 0.6881, 0.7653, 0.7246, 0.8624]\n",
      "e_5 * test rst: [0.00464, 0.7500, 0.6888, 0.7181, 0.8654]\n",
      "e_6 * test rst: [0.00491, 0.7627, 0.6888, 0.7239, 0.8678]\n",
      "e_7 * test rst: [0.00484, 0.6808, 0.7398, 0.7090, 0.8636]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00486, 0.6942, 0.7296, 0.7114, 0.8663]\n",
      "e_9 * test rst: [0.00514, 0.7120, 0.6939, 0.7028, 0.8654]\n",
      "e_10 * test rst: [0.00534, 0.6842, 0.7296, 0.7062, 0.8640]\n",
      "e_11 * test rst: [0.00513, 0.7312, 0.6939, 0.7120, 0.8694]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00523, 0.6948, 0.7551, 0.7237, 0.8670]\n",
      "e_13 * test rst: [0.00516, 0.7316, 0.7092, 0.7202, 0.8688]\n",
      "e_14 * test rst: [0.00519, 0.7340, 0.7041, 0.7188, 0.8689]\n",
      "e_15 * test rst: [0.00512, 0.7344, 0.7194, 0.7268, 0.8673]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00511, 0.7330, 0.7143, 0.7235, 0.8678]\n",
      "e_17 * test rst: [0.00513, 0.7214, 0.7398, 0.7305, 0.8683]\n",
      "e_18 * test rst: [0.00511, 0.7245, 0.7245, 0.7245, 0.8684]\n",
      "training end, used 309.44 s\n",
      "(0.005109578993032499, 0.7244897959183674, 0.7244897959183674, 0.7244897959183674, 0.8683617861313463)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "4985 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00508, 0.6855, 0.5030, 0.5802, 0.7954]\n",
      "e_2 * test rst: [0.00500, 0.6992, 0.5089, 0.5890, 0.8079]\n",
      "e_3 * test rst: [0.00610, 0.8462, 0.3905, 0.5344, 0.8075]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00543, 0.7478, 0.5089, 0.6056, 0.8252]\n",
      "e_5 * test rst: [0.00535, 0.6644, 0.5740, 0.6159, 0.8152]\n",
      "e_6 * test rst: [0.00576, 0.7063, 0.5266, 0.6034, 0.8213]\n",
      "e_7 * test rst: [0.00591, 0.8000, 0.4734, 0.5948, 0.8216]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00544, 0.6790, 0.6509, 0.6647, 0.8329]\n",
      "e_9 * test rst: [0.00560, 0.6986, 0.6036, 0.6476, 0.8320]\n",
      "e_10 * test rst: [0.00537, 0.7447, 0.6213, 0.6774, 0.8394]\n",
      "e_11 * test rst: [0.00576, 0.7500, 0.5503, 0.6348, 0.8325]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00565, 0.7364, 0.5621, 0.6376, 0.8337]\n",
      "e_13 * test rst: [0.00582, 0.7603, 0.5444, 0.6345, 0.8330]\n",
      "e_14 * test rst: [0.00560, 0.7313, 0.5799, 0.6469, 0.8323]\n",
      "e_15 * test rst: [0.00561, 0.7143, 0.6213, 0.6646, 0.8326]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00584, 0.7027, 0.6154, 0.6562, 0.8312]\n",
      "e_17 * test rst: [0.00570, 0.7266, 0.5976, 0.6558, 0.8336]\n",
      "e_18 * test rst: [0.00576, 0.7239, 0.5740, 0.6403, 0.8347]\n",
      "training end, used 311.99 s\n",
      "(0.00575801624097858, 0.7238805970149254, 0.5739644970414202, 0.6402640264026402, 0.8346507671228751)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "4985 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00432, 0.7982, 0.5515, 0.6523, 0.8396]\n",
      "e_2 * test rst: [0.00430, 0.8257, 0.5455, 0.6569, 0.8535]\n",
      "e_3 * test rst: [0.00398, 0.7969, 0.6182, 0.6962, 0.8627]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00432, 0.7338, 0.6848, 0.7085, 0.8507]\n",
      "e_5 * test rst: [0.00428, 0.7500, 0.6909, 0.7192, 0.8554]\n",
      "e_6 * test rst: [0.00499, 0.6443, 0.7576, 0.6964, 0.8592]\n",
      "e_7 * test rst: [0.00452, 0.7535, 0.6485, 0.6971, 0.8544]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00440, 0.7534, 0.6667, 0.7074, 0.8571]\n",
      "e_9 * test rst: [0.00452, 0.7169, 0.7212, 0.7190, 0.8571]\n",
      "e_10 * test rst: [0.00456, 0.7250, 0.7030, 0.7138, 0.8567]\n",
      "e_11 * test rst: [0.00464, 0.7417, 0.6788, 0.7089, 0.8505]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00478, 0.7652, 0.6121, 0.6801, 0.8441]\n",
      "e_13 * test rst: [0.00464, 0.7169, 0.7212, 0.7190, 0.8563]\n",
      "e_14 * test rst: [0.00466, 0.7285, 0.6667, 0.6962, 0.8496]\n",
      "e_15 * test rst: [0.00457, 0.7358, 0.7091, 0.7222, 0.8513]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00466, 0.7329, 0.7152, 0.7239, 0.8509]\n",
      "e_17 * test rst: [0.00467, 0.7450, 0.6727, 0.7070, 0.8494]\n",
      "e_18 * test rst: [0.00498, 0.7153, 0.6242, 0.6667, 0.8463]\n",
      "training end, used 309.54 s\n",
      "(0.004978535981895236, 0.7152777777777778, 0.6242424242424243, 0.6666666666666666, 0.8463476070528967)\n",
      "total label sum 184.5\n",
      "0.0051615752054785325,0.6795580110497238,0.7235294117647059,0.7008547008547009,0.8644514294267325\n",
      "0.004759230689008325,0.718562874251497,0.7058823529411765,0.712166172106825,0.8947013920071847\n",
      "0.005109578993032499,0.7244897959183674,0.7244897959183674,0.7244897959183674,0.8683617861313463\n",
      "0.00575801624097858,0.7238805970149254,0.5739644970414202,0.6402640264026402,0.8346507671228751\n",
      "0.004978535981895236,0.7152777777777778,0.6242424242424243,0.6666666666666666,0.8463476070528967\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.005153387422078636, 0.7123538112024582, 0.6704216963816189, 0.6888882723898401, 0.8617025963482071]\n",
      "mlt train ended\n",
      "0.711679,0.672414,0.691489,0.856749\n"
     ]
    }
   ],
   "source": [
    "args.no_ambiguous_label = True\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.l2_weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv_aug(tar_feature, train_dev_idx, features_ss_aug), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00428, 0.7615, 0.5824, 0.6600, 0.8577]\n",
      "e_2 * test rst: [0.00434, 0.6667, 0.6941, 0.6801, 0.8583]\n",
      "e_3 * test rst: [0.00426, 0.8443, 0.6059, 0.7055, 0.8679]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00459, 0.8333, 0.6176, 0.7095, 0.8705]\n",
      "e_5 * test rst: [0.00438, 0.6736, 0.7647, 0.7163, 0.8676]\n",
      "e_6 * test rst: [0.00434, 0.7468, 0.6765, 0.7099, 0.8651]\n",
      "e_7 * test rst: [0.00445, 0.7102, 0.7353, 0.7225, 0.8687]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00458, 0.7151, 0.7235, 0.7193, 0.8688]\n",
      "e_9 * test rst: [0.00468, 0.7229, 0.7059, 0.7143, 0.8662]\n",
      "e_10 * test rst: [0.00471, 0.7186, 0.7059, 0.7122, 0.8633]\n",
      "e_11 * test rst: [0.00476, 0.6995, 0.7529, 0.7252, 0.8630]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00471, 0.7143, 0.7353, 0.7246, 0.8638]\n",
      "e_13 * test rst: [0.00468, 0.7566, 0.6765, 0.7143, 0.8651]\n",
      "e_14 * test rst: [0.00466, 0.6940, 0.7471, 0.7195, 0.8678]\n",
      "e_15 * test rst: [0.00471, 0.7468, 0.6941, 0.7195, 0.8643]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00466, 0.7613, 0.6941, 0.7262, 0.8639]\n",
      "e_17 * test rst: [0.00463, 0.7305, 0.7176, 0.7240, 0.8646]\n",
      "e_18 * test rst: [0.00464, 0.7209, 0.7294, 0.7251, 0.8654]\n",
      "training end, used 325.32 s\n",
      "(0.004637554890044417, 0.7209302325581395, 0.7294117647058823, 0.7251461988304093, 0.8653944020356235)\n",
      "total label sum 197.5\n",
      "0.004637554890044417,0.7209302325581395,0.7294117647058823,0.7251461988304093,0.8653944020356235\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.004637554890044417, 0.7209302325581395, 0.7294117647058823, 0.7251461988304093, 0.8653944020356235]\n",
      "mlt train ended\n",
      "0.720930,0.729412,0.725146,0.865394\n"
     ]
    }
   ],
   "source": [
    "args.no_ambiguous_label = True\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.l2_weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv_aug(tar_feature, train_dev_idx, features_ss_aug), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    break\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.no_ambiguous_label = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00409, 0.7118, 0.7118, 0.7118, 0.8532]\n",
      "e_2 * test rst: [0.00407, 0.7535, 0.6294, 0.6859, 0.8575]\n",
      "e_3 * test rst: [0.00388, 0.7241, 0.7412, 0.7326, 0.8707]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00405, 0.7902, 0.6647, 0.7220, 0.8663]\n",
      "e_5 * test rst: [0.00404, 0.7310, 0.7353, 0.7331, 0.8664]\n",
      "e_6 * test rst: [0.00433, 0.8058, 0.6588, 0.7249, 0.8652]\n",
      "e_7 * test rst: [0.00423, 0.7610, 0.7118, 0.7356, 0.8645]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00415, 0.7225, 0.7353, 0.7289, 0.8676]\n",
      "e_9 * test rst: [0.00426, 0.6717, 0.7824, 0.7228, 0.8724]\n",
      "e_10 * test rst: [0.00422, 0.7111, 0.7529, 0.7314, 0.8710]\n",
      "e_11 * test rst: [0.00436, 0.7625, 0.7176, 0.7394, 0.8685]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00428, 0.7305, 0.7176, 0.7240, 0.8681]\n",
      "e_13 * test rst: [0.00436, 0.7273, 0.7529, 0.7399, 0.8683]\n",
      "e_14 * test rst: [0.00436, 0.7011, 0.7588, 0.7288, 0.8709]\n",
      "e_15 * test rst: [0.00427, 0.7396, 0.7353, 0.7375, 0.8703]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00431, 0.7530, 0.7353, 0.7440, 0.8702]\n",
      "e_17 * test rst: [0.00430, 0.7299, 0.7471, 0.7384, 0.8708]\n",
      "e_18 * test rst: [0.00432, 0.7299, 0.7471, 0.7384, 0.8708]\n",
      "training end, used 310.04 s\n",
      "(0.004320633566241916, 0.7298850574712644, 0.7470588235294118, 0.7383720930232558, 0.8708277204011374)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00443, 0.7188, 0.6765, 0.6970, 0.8691]\n",
      "e_2 * test rst: [0.00457, 0.7308, 0.6706, 0.6994, 0.8737]\n",
      "e_3 * test rst: [0.00482, 0.6345, 0.7353, 0.6812, 0.8762]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00469, 0.6760, 0.7118, 0.6934, 0.8753]\n",
      "e_5 * test rst: [0.00448, 0.7317, 0.7059, 0.7186, 0.8850]\n",
      "e_6 * test rst: [0.00434, 0.7186, 0.7059, 0.7122, 0.8888]\n",
      "e_7 * test rst: [0.00446, 0.6816, 0.7176, 0.6991, 0.8883]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00448, 0.7676, 0.6412, 0.6987, 0.8912]\n",
      "e_9 * test rst: [0.00439, 0.6632, 0.7412, 0.7000, 0.8958]\n",
      "e_10 * test rst: [0.00435, 0.7438, 0.7000, 0.7212, 0.8934]\n",
      "e_11 * test rst: [0.00445, 0.7312, 0.6882, 0.7091, 0.8916]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00441, 0.7273, 0.7059, 0.7164, 0.8947]\n",
      "e_13 * test rst: [0.00436, 0.7389, 0.6824, 0.7095, 0.8957]\n",
      "e_14 * test rst: [0.00444, 0.7000, 0.7412, 0.7200, 0.8977]\n",
      "e_15 * test rst: [0.00444, 0.6961, 0.7412, 0.7179, 0.8966]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00438, 0.7126, 0.7294, 0.7209, 0.8965]\n",
      "e_17 * test rst: [0.00442, 0.7006, 0.7294, 0.7147, 0.8968]\n",
      "e_18 * test rst: [0.00445, 0.7358, 0.6882, 0.7112, 0.8944]\n",
      "training end, used 311.17 s\n",
      "(0.004448002770040218, 0.7358490566037735, 0.6882352941176471, 0.7112462006079028, 0.8943571321658433)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "4984 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00488, 0.6524, 0.6990, 0.6749, 0.8398]\n",
      "e_2 * test rst: [0.00432, 0.7337, 0.6888, 0.7105, 0.8545]\n",
      "e_3 * test rst: [0.00475, 0.7059, 0.6735, 0.6893, 0.8500]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00472, 0.6833, 0.7704, 0.7242, 0.8572]\n",
      "e_5 * test rst: [0.00459, 0.7157, 0.7449, 0.7300, 0.8667]\n",
      "e_6 * test rst: [0.00471, 0.6981, 0.7551, 0.7255, 0.8683]\n",
      "e_7 * test rst: [0.00468, 0.7009, 0.7653, 0.7317, 0.8719]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00475, 0.7070, 0.7755, 0.7397, 0.8721]\n",
      "e_9 * test rst: [0.00471, 0.7268, 0.7194, 0.7231, 0.8761]\n",
      "e_10 * test rst: [0.00495, 0.6711, 0.7704, 0.7173, 0.8730]\n",
      "e_11 * test rst: [0.00489, 0.7030, 0.7245, 0.7136, 0.8745]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00497, 0.6898, 0.7602, 0.7233, 0.8743]\n",
      "e_13 * test rst: [0.00484, 0.6995, 0.7602, 0.7286, 0.8744]\n",
      "e_14 * test rst: [0.00482, 0.7150, 0.7296, 0.7222, 0.8754]\n",
      "e_15 * test rst: [0.00505, 0.6881, 0.7653, 0.7246, 0.8735]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00498, 0.6881, 0.7653, 0.7246, 0.8740]\n",
      "e_17 * test rst: [0.00490, 0.7028, 0.7602, 0.7304, 0.8753]\n",
      "e_18 * test rst: [0.00486, 0.6995, 0.7602, 0.7286, 0.8748]\n",
      "training end, used 313.16 s\n",
      "(0.004855950000707464, 0.6995305164319249, 0.7602040816326531, 0.7286063569682152, 0.874784518712117)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "4985 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00520, 0.6242, 0.5799, 0.6012, 0.7988]\n",
      "e_2 * test rst: [0.00530, 0.6250, 0.5621, 0.5919, 0.7980]\n",
      "e_3 * test rst: [0.00532, 0.6711, 0.5917, 0.6289, 0.8109]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00510, 0.6906, 0.5680, 0.6234, 0.8242]\n",
      "e_5 * test rst: [0.00528, 0.6358, 0.6509, 0.6433, 0.8300]\n",
      "e_6 * test rst: [0.00521, 0.7481, 0.5799, 0.6533, 0.8230]\n",
      "e_7 * test rst: [0.00510, 0.7344, 0.5562, 0.6330, 0.8291]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00498, 0.6948, 0.6331, 0.6625, 0.8372]\n",
      "e_9 * test rst: [0.00517, 0.6933, 0.6154, 0.6520, 0.8347]\n",
      "e_10 * test rst: [0.00532, 0.7557, 0.5858, 0.6600, 0.8357]\n",
      "e_11 * test rst: [0.00519, 0.6948, 0.6331, 0.6625, 0.8399]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00516, 0.6903, 0.6331, 0.6605, 0.8404]\n",
      "e_13 * test rst: [0.00519, 0.6937, 0.6568, 0.6748, 0.8405]\n",
      "e_14 * test rst: [0.00521, 0.6908, 0.6213, 0.6542, 0.8403]\n",
      "e_15 * test rst: [0.00510, 0.6879, 0.6391, 0.6626, 0.8419]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00516, 0.6894, 0.6568, 0.6727, 0.8427]\n",
      "e_17 * test rst: [0.00511, 0.6962, 0.6509, 0.6728, 0.8440]\n",
      "e_18 * test rst: [0.00522, 0.6855, 0.6450, 0.6646, 0.8412]\n",
      "training end, used 309.75 s\n",
      "(0.005221198952601049, 0.6855345911949685, 0.6449704142011834, 0.6646341463414633, 0.8412304078775011)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "4985 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00433, 0.7534, 0.6667, 0.7074, 0.8458]\n",
      "e_2 * test rst: [0.00404, 0.6940, 0.7697, 0.7299, 0.8727]\n",
      "e_3 * test rst: [0.00364, 0.7756, 0.7333, 0.7539, 0.8825]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00396, 0.8000, 0.6303, 0.7051, 0.8723]\n",
      "e_5 * test rst: [0.00452, 0.6238, 0.7939, 0.6987, 0.8817]\n",
      "e_6 * test rst: [0.00394, 0.7200, 0.7636, 0.7412, 0.8828]\n",
      "e_7 * test rst: [0.00428, 0.6919, 0.7758, 0.7314, 0.8811]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00409, 0.7267, 0.7576, 0.7418, 0.8825]\n",
      "e_9 * test rst: [0.00423, 0.7394, 0.7394, 0.7394, 0.8772]\n",
      "e_10 * test rst: [0.00432, 0.7151, 0.7455, 0.7300, 0.8801]\n",
      "e_11 * test rst: [0.00415, 0.7235, 0.7455, 0.7343, 0.8800]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00430, 0.6833, 0.7455, 0.7130, 0.8812]\n",
      "e_13 * test rst: [0.00410, 0.7531, 0.7394, 0.7462, 0.8764]\n",
      "e_14 * test rst: [0.00422, 0.7235, 0.7455, 0.7343, 0.8761]\n",
      "e_15 * test rst: [0.00417, 0.7365, 0.7455, 0.7410, 0.8764]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00447, 0.7022, 0.7576, 0.7289, 0.8756]\n",
      "e_17 * test rst: [0.00429, 0.7110, 0.7455, 0.7278, 0.8751]\n",
      "e_18 * test rst: [0.00432, 0.7151, 0.7455, 0.7300, 0.8741]\n",
      "training end, used 310.64 s\n",
      "(0.004323586516639092, 0.7151162790697675, 0.7454545454545455, 0.7299703264094957, 0.874085947637585)\n",
      "total label sum 184.5\n",
      "0.004320633566241916,0.7298850574712644,0.7470588235294118,0.7383720930232558,0.8708277204011374\n",
      "0.004448002770040218,0.7358490566037735,0.6882352941176471,0.7112462006079028,0.8943571321658433\n",
      "0.004855950000707464,0.6995305164319249,0.7602040816326531,0.7286063569682152,0.874784518712117\n",
      "0.005221198952601049,0.6855345911949685,0.6449704142011834,0.6646341463414633,0.8412304078775011\n",
      "0.004323586516639092,0.7151162790697675,0.7454545454545455,0.7299703264094957,0.874085947637585\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.004633874361245948, 0.7131831001543397, 0.7171846317870882, 0.7145658246700666, 0.8710571453588368]\n",
      "mlt train ended\n",
      "0.712657,0.718391,0.715512,0.869120\n"
     ]
    }
   ],
   "source": [
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.l2_weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv_aug(tar_feature, train_dev_idx, features_ss_aug), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "500 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00674, 1.0000, 0.0000, 0.0000, 0.7596]\n",
      "e_2 * test rst: [0.00843, 0.3618, 0.9471, 0.5236, 0.7982]\n",
      "e_3 * test rst: [0.00470, 0.6564, 0.6294, 0.6426, 0.8214]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00486, 0.5701, 0.7412, 0.6445, 0.8192]\n",
      "e_5 * test rst: [0.00534, 0.5479, 0.8412, 0.6636, 0.8241]\n",
      "e_6 * test rst: [0.00467, 0.6283, 0.7059, 0.6648, 0.8236]\n",
      "e_7 * test rst: [0.00480, 0.6238, 0.7412, 0.6774, 0.8357]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00491, 0.6448, 0.6941, 0.6686, 0.8298]\n",
      "e_9 * test rst: [0.00524, 0.7080, 0.5706, 0.6319, 0.8244]\n",
      "e_10 * test rst: [0.00511, 0.6752, 0.6235, 0.6483, 0.8296]\n",
      "e_11 * test rst: [0.00501, 0.6667, 0.6353, 0.6506, 0.8278]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00489, 0.6378, 0.6941, 0.6648, 0.8306]\n",
      "e_13 * test rst: [0.00502, 0.6310, 0.6941, 0.6611, 0.8327]\n",
      "e_14 * test rst: [0.00503, 0.6350, 0.7471, 0.6865, 0.8340]\n",
      "e_15 * test rst: [0.00512, 0.6500, 0.6882, 0.6686, 0.8313]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00518, 0.6477, 0.6706, 0.6590, 0.8326]\n",
      "e_17 * test rst: [0.00515, 0.6364, 0.7000, 0.6667, 0.8334]\n",
      "e_18 * test rst: [0.00523, 0.6369, 0.6706, 0.6533, 0.8325]\n",
      "training end, used 35.38 s\n",
      "(0.005229096509000124, 0.6368715083798883, 0.6705882352941176, 0.6532951289398281, 0.8324951354587637)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "500 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00661, 1.0000, 0.0000, 0.0000, 0.8389]\n",
      "e_2 * test rst: [0.00470, 0.6552, 0.6706, 0.6628, 0.8516]\n",
      "e_3 * test rst: [0.00499, 0.5890, 0.7588, 0.6632, 0.8497]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00579, 0.5222, 0.8294, 0.6409, 0.8447]\n",
      "e_5 * test rst: [0.00533, 0.5907, 0.7471, 0.6597, 0.8558]\n",
      "e_6 * test rst: [0.00540, 0.5620, 0.8000, 0.6602, 0.8525]\n",
      "e_7 * test rst: [0.00518, 0.6484, 0.6941, 0.6705, 0.8562]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00504, 0.7200, 0.6353, 0.6750, 0.8553]\n",
      "e_9 * test rst: [0.00530, 0.6467, 0.7000, 0.6723, 0.8568]\n",
      "e_10 * test rst: [0.00520, 0.6784, 0.6824, 0.6804, 0.8581]\n",
      "e_11 * test rst: [0.00518, 0.7063, 0.6647, 0.6848, 0.8560]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00524, 0.6914, 0.6588, 0.6747, 0.8564]\n",
      "e_13 * test rst: [0.00547, 0.6364, 0.7000, 0.6667, 0.8589]\n",
      "e_14 * test rst: [0.00531, 0.7044, 0.6588, 0.6809, 0.8556]\n",
      "e_15 * test rst: [0.00538, 0.6871, 0.6588, 0.6727, 0.8565]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00546, 0.6667, 0.6824, 0.6744, 0.8571]\n",
      "e_17 * test rst: [0.00542, 0.6871, 0.6588, 0.6727, 0.8564]\n",
      "e_18 * test rst: [0.00542, 0.6914, 0.6588, 0.6747, 0.8564]\n",
      "training end, used 35.41 s\n",
      "(0.0054215119910123715, 0.691358024691358, 0.6588235294117647, 0.674698795180723, 0.8564286783415656)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "500 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00707, 1.0000, 0.0000, 0.0000, 0.7632]\n",
      "e_2 * test rst: [0.00642, 0.7885, 0.4184, 0.5467, 0.8041]\n",
      "e_3 * test rst: [0.00546, 0.6705, 0.5918, 0.6287, 0.7969]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00577, 0.6988, 0.5918, 0.6409, 0.8116]\n",
      "e_5 * test rst: [0.00560, 0.7612, 0.5204, 0.6182, 0.8149]\n",
      "e_6 * test rst: [0.00593, 0.7519, 0.5102, 0.6079, 0.8214]\n",
      "e_7 * test rst: [0.00609, 0.7727, 0.5204, 0.6220, 0.8185]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00540, 0.7151, 0.6276, 0.6685, 0.8188]\n",
      "e_9 * test rst: [0.00597, 0.5904, 0.7500, 0.6607, 0.8171]\n",
      "e_10 * test rst: [0.00552, 0.6828, 0.6480, 0.6649, 0.8223]\n",
      "e_11 * test rst: [0.00590, 0.7273, 0.5714, 0.6400, 0.8231]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00560, 0.6526, 0.7092, 0.6797, 0.8236]\n",
      "e_13 * test rst: [0.00569, 0.7006, 0.6327, 0.6649, 0.8237]\n",
      "e_14 * test rst: [0.00568, 0.6603, 0.7041, 0.6815, 0.8241]\n",
      "e_15 * test rst: [0.00576, 0.6910, 0.6276, 0.6578, 0.8239]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00574, 0.6700, 0.6837, 0.6768, 0.8237]\n",
      "e_17 * test rst: [0.00578, 0.6634, 0.6939, 0.6783, 0.8234]\n",
      "e_18 * test rst: [0.00580, 0.6735, 0.6735, 0.6735, 0.8235]\n",
      "training end, used 35.76 s\n",
      "(0.005797962206506814, 0.673469387755102, 0.673469387755102, 0.673469387755102, 0.8234721681588166)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "500 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00694, 1.0000, 0.0000, 0.0000, 0.7211]\n",
      "e_2 * test rst: [0.00576, 0.5371, 0.5562, 0.5465, 0.7493]\n",
      "e_3 * test rst: [0.00557, 0.6698, 0.4201, 0.5164, 0.7819]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00563, 0.6545, 0.4260, 0.5161, 0.7806]\n",
      "e_5 * test rst: [0.00581, 0.7556, 0.4024, 0.5251, 0.7794]\n",
      "e_6 * test rst: [0.00540, 0.6640, 0.4911, 0.5646, 0.7842]\n",
      "e_7 * test rst: [0.00533, 0.6449, 0.5266, 0.5798, 0.7902]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00599, 0.8250, 0.3905, 0.5301, 0.7897]\n",
      "e_9 * test rst: [0.00543, 0.6026, 0.5562, 0.5785, 0.7946]\n",
      "e_10 * test rst: [0.00551, 0.5988, 0.5917, 0.5952, 0.7922]\n",
      "e_11 * test rst: [0.00572, 0.6327, 0.5503, 0.5886, 0.7918]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00580, 0.6742, 0.5266, 0.5914, 0.7904]\n",
      "e_13 * test rst: [0.00578, 0.6115, 0.5680, 0.5890, 0.7912]\n",
      "e_14 * test rst: [0.00589, 0.6069, 0.6213, 0.6140, 0.7904]\n",
      "e_15 * test rst: [0.00584, 0.6154, 0.5680, 0.5908, 0.7901]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00588, 0.6414, 0.5503, 0.5924, 0.7900]\n",
      "e_17 * test rst: [0.00598, 0.6291, 0.5621, 0.5938, 0.7890]\n",
      "e_18 * test rst: [0.00602, 0.6458, 0.5503, 0.5942, 0.7885]\n",
      "training end, used 35.34 s\n",
      "(0.006022691938800744, 0.6458333333333334, 0.5502958579881657, 0.5942492012779553, 0.7885330562958279)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "500 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00663, 1.0000, 0.0000, 0.0000, 0.8107]\n",
      "e_2 * test rst: [0.00546, 0.5325, 0.7455, 0.6212, 0.8082]\n",
      "e_3 * test rst: [0.00478, 0.7879, 0.4727, 0.5909, 0.8237]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00471, 0.6348, 0.6848, 0.6589, 0.8256]\n",
      "e_5 * test rst: [0.00451, 0.7561, 0.5636, 0.6458, 0.8330]\n",
      "e_6 * test rst: [0.00484, 0.7417, 0.5394, 0.6246, 0.8205]\n",
      "e_7 * test rst: [0.00483, 0.8056, 0.5273, 0.6374, 0.8133]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00456, 0.7183, 0.6182, 0.6645, 0.8194]\n",
      "e_9 * test rst: [0.00472, 0.6437, 0.6788, 0.6608, 0.8247]\n",
      "e_10 * test rst: [0.00468, 0.6774, 0.6364, 0.6562, 0.8256]\n",
      "e_11 * test rst: [0.00536, 0.6122, 0.7273, 0.6648, 0.8238]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00493, 0.6647, 0.6727, 0.6687, 0.8214]\n",
      "e_13 * test rst: [0.00483, 0.6818, 0.6364, 0.6583, 0.8221]\n",
      "e_14 * test rst: [0.00505, 0.6400, 0.6788, 0.6588, 0.8204]\n",
      "e_15 * test rst: [0.00501, 0.6667, 0.6667, 0.6667, 0.8181]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00511, 0.6550, 0.6788, 0.6667, 0.8174]\n",
      "e_17 * test rst: [0.00501, 0.6792, 0.6545, 0.6667, 0.8161]\n",
      "e_18 * test rst: [0.00509, 0.6667, 0.6667, 0.6667, 0.8157]\n",
      "training end, used 35.70 s\n",
      "(0.005087302686162691, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.8157316235401879)\n",
      "total label sum 184.5\n",
      "0.005229096509000124,0.6368715083798883,0.6705882352941176,0.6532951289398281,0.8324951354587637\n",
      "0.0054215119910123715,0.691358024691358,0.6588235294117647,0.674698795180723,0.8564286783415656\n",
      "0.005797962206506814,0.673469387755102,0.673469387755102,0.673469387755102,0.8234721681588166\n",
      "0.006022691938800744,0.6458333333333334,0.5502958579881657,0.5942492012779553,0.7885330562958279\n",
      "0.005087302686162691,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8157316235401879\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.005511713066296549, 0.6628397841652697, 0.6439687354231632, 0.652475835964055, 0.8233321323590322]\n",
      "mlt train ended\n",
      "0.663121,0.644828,0.653846,0.817134\n"
     ]
    }
   ],
   "source": [
    "train_s_sz = 500\n",
    "\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "args.l2_weight_decay = 1e-4\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    train_dev_idx = train_dev_idx[:train_s_sz]\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv(tar_feature, train_dev_idx), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "1000 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00485, 0.7217, 0.4882, 0.5825, 0.8195]\n",
      "e_2 * test rst: [0.00607, 0.8393, 0.2765, 0.4159, 0.8056]\n",
      "e_3 * test rst: [0.00451, 0.6486, 0.7059, 0.6761, 0.8342]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00465, 0.7133, 0.6294, 0.6687, 0.8307]\n",
      "e_5 * test rst: [0.00477, 0.6425, 0.6765, 0.6590, 0.8305]\n",
      "e_6 * test rst: [0.00478, 0.6848, 0.6647, 0.6746, 0.8347]\n",
      "e_7 * test rst: [0.00495, 0.6313, 0.7353, 0.6793, 0.8351]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00491, 0.6805, 0.6765, 0.6785, 0.8346]\n",
      "e_9 * test rst: [0.00508, 0.6704, 0.7059, 0.6877, 0.8326]\n",
      "e_10 * test rst: [0.00513, 0.6826, 0.6706, 0.6766, 0.8320]\n",
      "e_11 * test rst: [0.00538, 0.6181, 0.7235, 0.6667, 0.8312]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00519, 0.6614, 0.7353, 0.6964, 0.8341]\n",
      "e_13 * test rst: [0.00531, 0.6219, 0.7353, 0.6739, 0.8329]\n",
      "e_14 * test rst: [0.00532, 0.6188, 0.7353, 0.6720, 0.8339]\n",
      "e_15 * test rst: [0.00522, 0.6802, 0.6882, 0.6842, 0.8343]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00528, 0.6458, 0.7294, 0.6851, 0.8342]\n",
      "e_17 * test rst: [0.00533, 0.6474, 0.7235, 0.6833, 0.8337]\n",
      "e_18 * test rst: [0.00529, 0.6782, 0.6941, 0.6860, 0.8337]\n",
      "training end, used 66.00 s\n",
      "(0.005289771681780501, 0.6781609195402298, 0.6941176470588235, 0.6860465116279069, 0.8336775931746745)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "1000 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00504, 0.6458, 0.7294, 0.6851, 0.8538]\n",
      "e_2 * test rst: [0.00519, 0.7553, 0.4176, 0.5379, 0.8401]\n",
      "e_3 * test rst: [0.00459, 0.6263, 0.7294, 0.6739, 0.8540]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00503, 0.6386, 0.7588, 0.6935, 0.8646]\n",
      "e_5 * test rst: [0.00492, 0.6954, 0.6176, 0.6542, 0.8646]\n",
      "e_6 * test rst: [0.00539, 0.6055, 0.7765, 0.6804, 0.8671]\n",
      "e_7 * test rst: [0.00492, 0.6790, 0.6471, 0.6627, 0.8671]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00501, 0.6730, 0.6294, 0.6505, 0.8628]\n",
      "e_9 * test rst: [0.00496, 0.6522, 0.7059, 0.6780, 0.8691]\n",
      "e_10 * test rst: [0.00519, 0.6867, 0.6706, 0.6786, 0.8626]\n",
      "e_11 * test rst: [0.00507, 0.6489, 0.7176, 0.6816, 0.8717]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00517, 0.6871, 0.6588, 0.6727, 0.8656]\n",
      "e_13 * test rst: [0.00516, 0.6890, 0.6647, 0.6766, 0.8656]\n",
      "e_14 * test rst: [0.00526, 0.6918, 0.6471, 0.6687, 0.8629]\n",
      "e_15 * test rst: [0.00518, 0.6780, 0.7059, 0.6916, 0.8689]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00520, 0.6848, 0.6647, 0.6746, 0.8654]\n",
      "e_17 * test rst: [0.00525, 0.6848, 0.6647, 0.6746, 0.8645]\n",
      "e_18 * test rst: [0.00523, 0.6905, 0.6824, 0.6864, 0.8656]\n",
      "training end, used 66.23 s\n",
      "(0.005232901790478725, 0.6904761904761905, 0.6823529411764706, 0.6863905325443787, 0.8656189193234545)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "1000 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00639, 0.5151, 0.7857, 0.6222, 0.7895]\n",
      "e_2 * test rst: [0.00553, 0.5755, 0.7194, 0.6395, 0.8023]\n",
      "e_3 * test rst: [0.00514, 0.7557, 0.5051, 0.6055, 0.8105]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00574, 0.5924, 0.7194, 0.6498, 0.8186]\n",
      "e_5 * test rst: [0.00539, 0.6667, 0.6633, 0.6650, 0.8097]\n",
      "e_6 * test rst: [0.00600, 0.7372, 0.5153, 0.6066, 0.8128]\n",
      "e_7 * test rst: [0.00606, 0.6250, 0.7143, 0.6667, 0.8085]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00598, 0.6703, 0.6224, 0.6455, 0.8084]\n",
      "e_9 * test rst: [0.00637, 0.6099, 0.6939, 0.6492, 0.8091]\n",
      "e_10 * test rst: [0.00626, 0.6505, 0.6837, 0.6667, 0.8090]\n",
      "e_11 * test rst: [0.00652, 0.5950, 0.7347, 0.6575, 0.8079]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00626, 0.6351, 0.6837, 0.6585, 0.8105]\n",
      "e_13 * test rst: [0.00635, 0.6326, 0.6939, 0.6618, 0.8090]\n",
      "e_14 * test rst: [0.00633, 0.6337, 0.6531, 0.6432, 0.8101]\n",
      "e_15 * test rst: [0.00632, 0.6359, 0.6684, 0.6517, 0.8107]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00640, 0.6414, 0.6480, 0.6447, 0.8114]\n",
      "e_17 * test rst: [0.00648, 0.6324, 0.6582, 0.6450, 0.8115]\n",
      "e_18 * test rst: [0.00653, 0.6308, 0.6888, 0.6585, 0.8120]\n",
      "training end, used 66.47 s\n",
      "(0.006530242361670912, 0.6308411214953271, 0.6887755102040817, 0.6585365853658538, 0.8120308068731579)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "1000 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00591, 0.5381, 0.6686, 0.5963, 0.7505]\n",
      "e_2 * test rst: [0.00540, 0.5741, 0.5503, 0.5619, 0.7731]\n",
      "e_3 * test rst: [0.00610, 0.8333, 0.2367, 0.3687, 0.7810]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00525, 0.6168, 0.6095, 0.6131, 0.7863]\n",
      "e_5 * test rst: [0.00518, 0.6506, 0.6391, 0.6448, 0.7865]\n",
      "e_6 * test rst: [0.00553, 0.6150, 0.6805, 0.6461, 0.7868]\n",
      "e_7 * test rst: [0.00528, 0.6917, 0.5444, 0.6093, 0.7911]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00542, 0.6603, 0.6095, 0.6338, 0.7901]\n",
      "e_9 * test rst: [0.00553, 0.6337, 0.6450, 0.6393, 0.7893]\n",
      "e_10 * test rst: [0.00555, 0.6456, 0.6036, 0.6239, 0.7879]\n",
      "e_11 * test rst: [0.00562, 0.6689, 0.5976, 0.6313, 0.7900]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00560, 0.6478, 0.6095, 0.6280, 0.7882]\n",
      "e_13 * test rst: [0.00583, 0.6412, 0.6450, 0.6431, 0.7865]\n",
      "e_14 * test rst: [0.00575, 0.6380, 0.6154, 0.6265, 0.7877]\n",
      "e_15 * test rst: [0.00580, 0.6375, 0.6036, 0.6201, 0.7877]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00586, 0.6398, 0.6095, 0.6242, 0.7867]\n",
      "e_17 * test rst: [0.00590, 0.6398, 0.6095, 0.6242, 0.7864]\n",
      "e_18 * test rst: [0.00588, 0.6398, 0.6095, 0.6242, 0.7869]\n",
      "training end, used 65.67 s\n",
      "(0.005878518484665406, 0.639751552795031, 0.6094674556213018, 0.6242424242424243, 0.7868919102037129)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "1000 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00515, 0.7043, 0.4909, 0.5786, 0.7864]\n",
      "e_2 * test rst: [0.00470, 0.7333, 0.5333, 0.6175, 0.8125]\n",
      "e_3 * test rst: [0.00459, 0.6886, 0.6970, 0.6928, 0.8417]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00537, 0.5857, 0.7455, 0.6560, 0.8353]\n",
      "e_5 * test rst: [0.00471, 0.6590, 0.6909, 0.6746, 0.8332]\n",
      "e_6 * test rst: [0.00462, 0.7051, 0.6667, 0.6854, 0.8346]\n",
      "e_7 * test rst: [0.00473, 0.7192, 0.6364, 0.6752, 0.8258]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00540, 0.6000, 0.7636, 0.6720, 0.8324]\n",
      "e_9 * test rst: [0.00500, 0.6505, 0.7333, 0.6895, 0.8287]\n",
      "e_10 * test rst: [0.00470, 0.7025, 0.6727, 0.6873, 0.8266]\n",
      "e_11 * test rst: [0.00506, 0.6536, 0.7091, 0.6802, 0.8275]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00511, 0.6500, 0.7091, 0.6783, 0.8273]\n",
      "e_13 * test rst: [0.00516, 0.6556, 0.7152, 0.6841, 0.8249]\n",
      "e_14 * test rst: [0.00510, 0.6628, 0.6909, 0.6766, 0.8235]\n",
      "e_15 * test rst: [0.00514, 0.6667, 0.7030, 0.6844, 0.8236]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00522, 0.6591, 0.7030, 0.6804, 0.8225]\n",
      "e_17 * test rst: [0.00530, 0.6591, 0.7030, 0.6804, 0.8221]\n",
      "e_18 * test rst: [0.00535, 0.6517, 0.7030, 0.6764, 0.8218]\n",
      "training end, used 66.00 s\n",
      "(0.005351491743082254, 0.651685393258427, 0.703030303030303, 0.6763848396501458, 0.8218303946263643)\n",
      "total label sum 184.5\n",
      "0.005289771681780501,0.6781609195402298,0.6941176470588235,0.6860465116279069,0.8336775931746745\n",
      "0.005232901790478725,0.6904761904761905,0.6823529411764706,0.6863905325443787,0.8656189193234545\n",
      "0.006530242361670912,0.6308411214953271,0.6887755102040817,0.6585365853658538,0.8120308068731579\n",
      "0.005878518484665406,0.639751552795031,0.6094674556213018,0.6242424242424243,0.7868919102037129\n",
      "0.005351491743082254,0.651685393258427,0.703030303030303,0.6763848396501458,0.8218303946263643\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.00565658521233556, 0.658183035513041, 0.6755487714181962, 0.6663201786861419, 0.8240099248402728]\n",
      "mlt train ended\n",
      "0.656983,0.675862,0.666289,0.816887\n"
     ]
    }
   ],
   "source": [
    "train_s_sz = 1000\n",
    "\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "args.l2_weight_decay = 1e-4\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    train_dev_idx = train_dev_idx[:train_s_sz]\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv(tar_feature, train_dev_idx), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "1500 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00494, 0.6601, 0.5941, 0.6254, 0.8121]\n",
      "e_2 * test rst: [0.00476, 0.7524, 0.4647, 0.5745, 0.8259]\n",
      "e_3 * test rst: [0.00442, 0.7107, 0.6647, 0.6869, 0.8380]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00476, 0.7698, 0.5706, 0.6554, 0.8423]\n",
      "e_5 * test rst: [0.00515, 0.5422, 0.7941, 0.6444, 0.8405]\n",
      "e_6 * test rst: [0.00461, 0.6095, 0.7529, 0.6737, 0.8430]\n",
      "e_7 * test rst: [0.00480, 0.7778, 0.5765, 0.6622, 0.8427]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00465, 0.7063, 0.6647, 0.6848, 0.8443]\n",
      "e_9 * test rst: [0.00477, 0.6821, 0.6941, 0.6880, 0.8429]\n",
      "e_10 * test rst: [0.00480, 0.6842, 0.6882, 0.6862, 0.8449]\n",
      "e_11 * test rst: [0.00482, 0.7467, 0.6588, 0.7000, 0.8408]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00485, 0.6933, 0.6647, 0.6787, 0.8430]\n",
      "e_13 * test rst: [0.00508, 0.6443, 0.7353, 0.6868, 0.8420]\n",
      "e_14 * test rst: [0.00484, 0.6890, 0.6647, 0.6766, 0.8434]\n",
      "e_15 * test rst: [0.00491, 0.6933, 0.6647, 0.6787, 0.8412]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00491, 0.6864, 0.6824, 0.6844, 0.8428]\n",
      "e_17 * test rst: [0.00494, 0.6839, 0.7000, 0.6919, 0.8434]\n",
      "e_18 * test rst: [0.00494, 0.6786, 0.6706, 0.6746, 0.8428]\n",
      "training end, used 97.34 s\n",
      "(0.004939408221846152, 0.6785714285714286, 0.6705882352941176, 0.6745562130177514, 0.8427929950606197)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "1500 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00521, 0.8158, 0.3647, 0.5041, 0.8377]\n",
      "e_2 * test rst: [0.00484, 0.6527, 0.6412, 0.6469, 0.8502]\n",
      "e_3 * test rst: [0.00497, 0.6359, 0.7294, 0.6795, 0.8497]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00493, 0.6772, 0.6294, 0.6524, 0.8583]\n",
      "e_5 * test rst: [0.00510, 0.6957, 0.6588, 0.6767, 0.8571]\n",
      "e_6 * test rst: [0.00482, 0.6852, 0.6529, 0.6687, 0.8605]\n",
      "e_7 * test rst: [0.00558, 0.6231, 0.7294, 0.6721, 0.8565]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00516, 0.7115, 0.6529, 0.6810, 0.8550]\n",
      "e_9 * test rst: [0.00524, 0.6524, 0.7176, 0.6835, 0.8595]\n",
      "e_10 * test rst: [0.00522, 0.6933, 0.6647, 0.6787, 0.8583]\n",
      "e_11 * test rst: [0.00548, 0.6685, 0.7118, 0.6895, 0.8612]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00537, 0.6611, 0.7000, 0.6800, 0.8599]\n",
      "e_13 * test rst: [0.00546, 0.6611, 0.7000, 0.6800, 0.8589]\n",
      "e_14 * test rst: [0.00536, 0.6824, 0.6824, 0.6824, 0.8588]\n",
      "e_15 * test rst: [0.00538, 0.6705, 0.6824, 0.6764, 0.8597]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00544, 0.6648, 0.7118, 0.6875, 0.8614]\n",
      "e_17 * test rst: [0.00539, 0.6743, 0.6941, 0.6841, 0.8602]\n",
      "e_18 * test rst: [0.00546, 0.6648, 0.7118, 0.6875, 0.8607]\n",
      "training end, used 96.57 s\n",
      "(0.0054589010523648715, 0.6648351648351648, 0.711764705882353, 0.6875, 0.8606945068103578)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "1500 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00521, 0.7308, 0.5816, 0.6477, 0.8254]\n",
      "e_2 * test rst: [0.00493, 0.7208, 0.5663, 0.6343, 0.8287]\n",
      "e_3 * test rst: [0.00625, 0.4916, 0.8929, 0.6341, 0.8325]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00500, 0.6333, 0.7755, 0.6972, 0.8411]\n",
      "e_5 * test rst: [0.00490, 0.6711, 0.7806, 0.7217, 0.8445]\n",
      "e_6 * test rst: [0.00526, 0.6954, 0.6990, 0.6972, 0.8458]\n",
      "e_7 * test rst: [0.00531, 0.6593, 0.7602, 0.7062, 0.8381]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00530, 0.6757, 0.7653, 0.7177, 0.8402]\n",
      "e_9 * test rst: [0.00542, 0.6773, 0.7602, 0.7163, 0.8383]\n",
      "e_10 * test rst: [0.00566, 0.6456, 0.7806, 0.7067, 0.8362]\n",
      "e_11 * test rst: [0.00592, 0.6062, 0.8010, 0.6901, 0.8348]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00564, 0.6837, 0.7500, 0.7153, 0.8365]\n",
      "e_13 * test rst: [0.00568, 0.6806, 0.7500, 0.7136, 0.8368]\n",
      "e_14 * test rst: [0.00579, 0.6759, 0.7449, 0.7087, 0.8364]\n",
      "e_15 * test rst: [0.00581, 0.6834, 0.6939, 0.6886, 0.8359]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00580, 0.6774, 0.7500, 0.7119, 0.8345]\n",
      "e_17 * test rst: [0.00582, 0.6779, 0.7194, 0.6980, 0.8350]\n",
      "e_18 * test rst: [0.00588, 0.6794, 0.7245, 0.7012, 0.8352]\n",
      "training end, used 96.92 s\n",
      "(0.00587733550457082, 0.6794258373205742, 0.7244897959183674, 0.7012345679012346, 0.8351637657787911)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "1500 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00558, 0.6557, 0.4734, 0.5498, 0.7678]\n",
      "e_2 * test rst: [0.00537, 0.5942, 0.4852, 0.5342, 0.7749]\n",
      "e_3 * test rst: [0.00507, 0.6420, 0.6154, 0.6284, 0.8005]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00523, 0.6714, 0.5562, 0.6084, 0.7977]\n",
      "e_5 * test rst: [0.00567, 0.6415, 0.6036, 0.6220, 0.8027]\n",
      "e_6 * test rst: [0.00557, 0.6507, 0.5621, 0.6032, 0.7991]\n",
      "e_7 * test rst: [0.00549, 0.5989, 0.6627, 0.6292, 0.8041]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00567, 0.6600, 0.5858, 0.6207, 0.8006]\n",
      "e_9 * test rst: [0.00566, 0.6442, 0.6213, 0.6325, 0.8016]\n",
      "e_10 * test rst: [0.00584, 0.6337, 0.6450, 0.6393, 0.8018]\n",
      "e_11 * test rst: [0.00589, 0.6424, 0.6272, 0.6347, 0.8026]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00576, 0.6541, 0.6154, 0.6341, 0.8034]\n",
      "e_13 * test rst: [0.00583, 0.6689, 0.5976, 0.6313, 0.8030]\n",
      "e_14 * test rst: [0.00579, 0.6538, 0.6036, 0.6277, 0.8042]\n",
      "e_15 * test rst: [0.00589, 0.6601, 0.5976, 0.6273, 0.8040]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00589, 0.6541, 0.6154, 0.6341, 0.8040]\n",
      "e_17 * test rst: [0.00589, 0.6538, 0.6036, 0.6277, 0.8036]\n",
      "e_18 * test rst: [0.00590, 0.6623, 0.6036, 0.6316, 0.8038]\n",
      "training end, used 97.29 s\n",
      "(0.00590137111228556, 0.6623376623376623, 0.6035502958579881, 0.631578947368421, 0.8037701190960145)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "1500 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00531, 0.5368, 0.7515, 0.6263, 0.8154]\n",
      "e_2 * test rst: [0.00477, 0.6103, 0.7212, 0.6611, 0.8283]\n",
      "e_3 * test rst: [0.00455, 0.7768, 0.5273, 0.6282, 0.8461]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00438, 0.6613, 0.7455, 0.7009, 0.8560]\n",
      "e_5 * test rst: [0.00449, 0.6758, 0.7455, 0.7089, 0.8529]\n",
      "e_6 * test rst: [0.00431, 0.7035, 0.7333, 0.7181, 0.8498]\n",
      "e_7 * test rst: [0.00447, 0.7143, 0.7273, 0.7207, 0.8509]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00461, 0.6949, 0.7455, 0.7193, 0.8482]\n",
      "e_9 * test rst: [0.00458, 0.7284, 0.7152, 0.7217, 0.8423]\n",
      "e_10 * test rst: [0.00466, 0.7093, 0.7394, 0.7240, 0.8369]\n",
      "e_11 * test rst: [0.00473, 0.6954, 0.7333, 0.7139, 0.8374]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00476, 0.6914, 0.7333, 0.7118, 0.8385]\n",
      "e_13 * test rst: [0.00492, 0.6721, 0.7455, 0.7069, 0.8358]\n",
      "e_14 * test rst: [0.00509, 0.6632, 0.7636, 0.7099, 0.8344]\n",
      "e_15 * test rst: [0.00520, 0.6562, 0.7636, 0.7059, 0.8352]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00498, 0.6816, 0.7394, 0.7093, 0.8347]\n",
      "e_17 * test rst: [0.00513, 0.6685, 0.7455, 0.7049, 0.8347]\n",
      "e_18 * test rst: [0.00523, 0.6578, 0.7455, 0.6989, 0.8342]\n",
      "training end, used 98.16 s\n",
      "(0.005230676932956401, 0.6577540106951871, 0.7454545454545455, 0.6988636363636364, 0.8342111289214564)\n",
      "total label sum 184.5\n",
      "0.004939408221846152,0.6785714285714286,0.6705882352941176,0.6745562130177514,0.8427929950606197\n",
      "0.0054589010523648715,0.6648351648351648,0.711764705882353,0.6875,0.8606945068103578\n",
      "0.00587733550457082,0.6794258373205742,0.7244897959183674,0.7012345679012346,0.8351637657787911\n",
      "0.00590137111228556,0.6623376623376623,0.6035502958579881,0.631578947368421,0.8037701190960145\n",
      "0.005230676932956401,0.6577540106951871,0.7454545454545455,0.6988636363636364,0.8342111289214564\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.0054815385648047605, 0.6685848207520035, 0.6911695156814743, 0.6787466729302086, 0.835326503133448]\n",
      "mlt train ended\n",
      "0.668889,0.691954,0.680226,0.828261\n"
     ]
    }
   ],
   "source": [
    "train_s_sz = 1500\n",
    "\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "args.l2_weight_decay = 1e-4\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    train_dev_idx = train_dev_idx[:train_s_sz]\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv(tar_feature, train_dev_idx), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "2250 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00566, 0.8125, 0.3059, 0.4444, 0.8213]\n",
      "e_2 * test rst: [0.00431, 0.6882, 0.6882, 0.6882, 0.8370]\n",
      "e_3 * test rst: [0.00483, 0.8000, 0.5412, 0.6456, 0.8397]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00464, 0.6743, 0.6941, 0.6841, 0.8403]\n",
      "e_5 * test rst: [0.00465, 0.6905, 0.6824, 0.6864, 0.8463]\n",
      "e_6 * test rst: [0.00531, 0.5895, 0.7941, 0.6767, 0.8444]\n",
      "e_7 * test rst: [0.00472, 0.7879, 0.6118, 0.6887, 0.8404]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00462, 0.7059, 0.7059, 0.7059, 0.8458]\n",
      "e_9 * test rst: [0.00467, 0.7222, 0.6882, 0.7048, 0.8436]\n",
      "e_10 * test rst: [0.00467, 0.7436, 0.6824, 0.7117, 0.8460]\n",
      "e_11 * test rst: [0.00471, 0.7117, 0.6824, 0.6967, 0.8477]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00477, 0.7338, 0.6647, 0.6975, 0.8476]\n",
      "e_13 * test rst: [0.00477, 0.7178, 0.6882, 0.7027, 0.8488]\n",
      "e_14 * test rst: [0.00474, 0.7233, 0.6765, 0.6991, 0.8497]\n",
      "e_15 * test rst: [0.00479, 0.6875, 0.7118, 0.6994, 0.8521]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00480, 0.7041, 0.7000, 0.7021, 0.8501]\n",
      "e_17 * test rst: [0.00483, 0.6897, 0.7059, 0.6977, 0.8511]\n",
      "e_18 * test rst: [0.00484, 0.6936, 0.7059, 0.6997, 0.8518]\n",
      "training end, used 144.27 s\n",
      "(0.004842654611670526, 0.6936416184971098, 0.7058823529411765, 0.6997084548104957, 0.8518185900314323)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "2250 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00475, 0.7398, 0.5353, 0.6212, 0.8555]\n",
      "e_2 * test rst: [0.00464, 0.6864, 0.6824, 0.6844, 0.8667]\n",
      "e_3 * test rst: [0.00490, 0.7385, 0.5647, 0.6400, 0.8568]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00503, 0.7429, 0.6118, 0.6710, 0.8589]\n",
      "e_5 * test rst: [0.00477, 0.6648, 0.7118, 0.6875, 0.8634]\n",
      "e_6 * test rst: [0.00479, 0.7292, 0.6176, 0.6688, 0.8620]\n",
      "e_7 * test rst: [0.00466, 0.7273, 0.6588, 0.6914, 0.8651]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00513, 0.7179, 0.6588, 0.6871, 0.8609]\n",
      "e_9 * test rst: [0.00488, 0.6886, 0.6765, 0.6825, 0.8652]\n",
      "e_10 * test rst: [0.00499, 0.7244, 0.6647, 0.6933, 0.8621]\n",
      "e_11 * test rst: [0.00514, 0.7171, 0.6412, 0.6770, 0.8607]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00511, 0.7379, 0.6294, 0.6794, 0.8608]\n",
      "e_13 * test rst: [0.00518, 0.7255, 0.6529, 0.6873, 0.8615]\n",
      "e_14 * test rst: [0.00514, 0.7303, 0.6529, 0.6894, 0.8616]\n",
      "e_15 * test rst: [0.00515, 0.7273, 0.6588, 0.6914, 0.8610]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00515, 0.7303, 0.6529, 0.6894, 0.8616]\n",
      "e_17 * test rst: [0.00515, 0.7415, 0.6412, 0.6877, 0.8606]\n",
      "e_18 * test rst: [0.00515, 0.7432, 0.6471, 0.6918, 0.8608]\n",
      "training end, used 144.62 s\n",
      "(0.005145402737689696, 0.7432432432432432, 0.6470588235294118, 0.6918238993710691, 0.8607843137254901)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "2250 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00525, 0.6373, 0.6276, 0.6324, 0.8095]\n",
      "e_2 * test rst: [0.00485, 0.6701, 0.6735, 0.6718, 0.8248]\n",
      "e_3 * test rst: [0.00534, 0.6973, 0.6582, 0.6772, 0.8341]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00520, 0.6823, 0.6684, 0.6753, 0.8398]\n",
      "e_5 * test rst: [0.00538, 0.6620, 0.7296, 0.6942, 0.8404]\n",
      "e_6 * test rst: [0.00525, 0.6516, 0.7347, 0.6906, 0.8372]\n",
      "e_7 * test rst: [0.00555, 0.6383, 0.7653, 0.6961, 0.8463]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00529, 0.6620, 0.7296, 0.6942, 0.8470]\n",
      "e_9 * test rst: [0.00577, 0.6157, 0.7602, 0.6804, 0.8459]\n",
      "e_10 * test rst: [0.00579, 0.6198, 0.7653, 0.6849, 0.8446]\n",
      "e_11 * test rst: [0.00565, 0.6395, 0.7602, 0.6946, 0.8453]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00561, 0.6637, 0.7551, 0.7064, 0.8462]\n",
      "e_13 * test rst: [0.00562, 0.6606, 0.7449, 0.7002, 0.8456]\n",
      "e_14 * test rst: [0.00565, 0.6591, 0.7398, 0.6971, 0.8459]\n",
      "e_15 * test rst: [0.00571, 0.6520, 0.7551, 0.6998, 0.8464]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00568, 0.6591, 0.7398, 0.6971, 0.8451]\n",
      "e_17 * test rst: [0.00569, 0.6636, 0.7449, 0.7019, 0.8456]\n",
      "e_18 * test rst: [0.00569, 0.6621, 0.7398, 0.6988, 0.8462]\n",
      "training end, used 144.95 s\n",
      "(0.0056917830295926935, 0.6621004566210046, 0.7397959183673469, 0.6987951807228916, 0.8461602624701107)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "2251 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00622, 0.7600, 0.1124, 0.1959, 0.7685]\n",
      "e_2 * test rst: [0.00522, 0.5663, 0.6568, 0.6082, 0.7949]\n",
      "e_3 * test rst: [0.00513, 0.6056, 0.6450, 0.6246, 0.7936]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00553, 0.6552, 0.5621, 0.6051, 0.7940]\n",
      "e_5 * test rst: [0.00571, 0.6022, 0.6450, 0.6229, 0.7960]\n",
      "e_6 * test rst: [0.00562, 0.6415, 0.6036, 0.6220, 0.7940]\n",
      "e_7 * test rst: [0.00609, 0.5944, 0.6331, 0.6132, 0.7913]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00597, 0.6154, 0.6154, 0.6154, 0.7936]\n",
      "e_9 * test rst: [0.00603, 0.6483, 0.5562, 0.5987, 0.7946]\n",
      "e_10 * test rst: [0.00605, 0.6364, 0.5799, 0.6068, 0.7948]\n",
      "e_11 * test rst: [0.00598, 0.6306, 0.5858, 0.6074, 0.7946]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00614, 0.6370, 0.5503, 0.5905, 0.7942]\n",
      "e_13 * test rst: [0.00617, 0.6194, 0.5680, 0.5926, 0.7949]\n",
      "e_14 * test rst: [0.00628, 0.6327, 0.5503, 0.5886, 0.7947]\n",
      "e_15 * test rst: [0.00617, 0.6351, 0.5562, 0.5931, 0.7943]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00623, 0.6419, 0.5621, 0.5994, 0.7949]\n",
      "e_17 * test rst: [0.00626, 0.6458, 0.5503, 0.5942, 0.7953]\n",
      "e_18 * test rst: [0.00619, 0.6370, 0.5503, 0.5905, 0.7952]\n",
      "training end, used 144.47 s\n",
      "(0.006191744194018035, 0.636986301369863, 0.5502958579881657, 0.5904761904761905, 0.7951879789812848)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "2251 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00467, 0.7404, 0.4667, 0.5725, 0.8121]\n",
      "e_2 * test rst: [0.00434, 0.6629, 0.7030, 0.6824, 0.8357]\n",
      "e_3 * test rst: [0.00426, 0.6954, 0.6364, 0.6646, 0.8323]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00431, 0.6739, 0.7515, 0.7106, 0.8420]\n",
      "e_5 * test rst: [0.00527, 0.6168, 0.8000, 0.6966, 0.8449]\n",
      "e_6 * test rst: [0.00513, 0.6095, 0.7758, 0.6827, 0.8420]\n",
      "e_7 * test rst: [0.00448, 0.7202, 0.7333, 0.7267, 0.8402]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00487, 0.6418, 0.7818, 0.7049, 0.8461]\n",
      "e_9 * test rst: [0.00491, 0.6414, 0.7697, 0.6997, 0.8434]\n",
      "e_10 * test rst: [0.00463, 0.6796, 0.7455, 0.7110, 0.8394]\n",
      "e_11 * test rst: [0.00508, 0.6458, 0.7515, 0.6947, 0.8387]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00492, 0.6510, 0.7576, 0.7003, 0.8410]\n",
      "e_13 * test rst: [0.00508, 0.6410, 0.7576, 0.6944, 0.8436]\n",
      "e_14 * test rst: [0.00503, 0.6508, 0.7455, 0.6949, 0.8433]\n",
      "e_15 * test rst: [0.00500, 0.6508, 0.7455, 0.6949, 0.8430]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00515, 0.6480, 0.7697, 0.7036, 0.8426]\n",
      "e_17 * test rst: [0.00499, 0.6595, 0.7394, 0.6971, 0.8421]\n",
      "e_18 * test rst: [0.00513, 0.6492, 0.7515, 0.6966, 0.8417]\n",
      "training end, used 142.25 s\n",
      "(0.005129241328222471, 0.6492146596858639, 0.7515151515151515, 0.6966292134831461, 0.841660941912831)\n",
      "total label sum 184.5\n",
      "0.004842654611670526,0.6936416184971098,0.7058823529411765,0.6997084548104957,0.8518185900314323\n",
      "0.005145402737689696,0.7432432432432432,0.6470588235294118,0.6918238993710691,0.8607843137254901\n",
      "0.0056917830295926935,0.6621004566210046,0.7397959183673469,0.6987951807228916,0.8461602624701107\n",
      "0.006191744194018035,0.636986301369863,0.5502958579881657,0.5904761904761905,0.7951879789812848\n",
      "0.005129241328222471,0.6492146596858639,0.7515151515151515,0.6966292134831461,0.841660941912831\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.005400165180238685, 0.6770372558834169, 0.6789096208682505, 0.6754865877727585, 0.8391224174242298]\n",
      "mlt train ended\n",
      "0.675029,0.680460,0.677733,0.835435\n"
     ]
    }
   ],
   "source": [
    "# train_s_sz = 1500\n",
    "\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "args.l2_weight_decay = 1e-4\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    train_dev_idx = train_dev_idx[:]\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv(tar_feature, train_dev_idx), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.3,\n",
      " 'FC_dp': 0.1,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 100,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 18,\n",
      " 'l2_weight_decay': 0.0001,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 5.0,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 64,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 2,\n",
      " 'rnn_num_directions': 2,\n",
      " 'rnn_out_f_n': 68,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0.0001,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "2250 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00548, 0.8095, 0.3000, 0.4378, 0.8145]\n",
      "e_2 * test rst: [0.00559, 0.5550, 0.7118, 0.6237, 0.8157]\n",
      "e_3 * test rst: [0.00670, 0.7143, 0.2941, 0.4167, 0.7969]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00463, 0.6687, 0.6294, 0.6485, 0.8352]\n",
      "e_5 * test rst: [0.00475, 0.7500, 0.5647, 0.6443, 0.8343]\n",
      "e_6 * test rst: [0.00462, 0.7114, 0.6235, 0.6646, 0.8389]\n",
      "e_7 * test rst: [0.00490, 0.6219, 0.7353, 0.6739, 0.8421]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00487, 0.7442, 0.5647, 0.6421, 0.8340]\n",
      "e_9 * test rst: [0.00473, 0.7574, 0.6059, 0.6732, 0.8372]\n",
      "e_10 * test rst: [0.00484, 0.7115, 0.6529, 0.6810, 0.8387]\n",
      "e_11 * test rst: [0.00486, 0.6725, 0.6765, 0.6745, 0.8407]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00547, 0.5733, 0.7824, 0.6617, 0.8416]\n",
      "e_13 * test rst: [0.00545, 0.5804, 0.7647, 0.6599, 0.8417]\n",
      "e_14 * test rst: [0.00528, 0.5860, 0.7412, 0.6545, 0.8426]\n",
      "e_15 * test rst: [0.00534, 0.5841, 0.7353, 0.6510, 0.8439]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00474, 0.7000, 0.6588, 0.6788, 0.8431]\n",
      "e_17 * test rst: [0.00474, 0.7315, 0.6412, 0.6834, 0.8414]\n",
      "e_18 * test rst: [0.00477, 0.7466, 0.6412, 0.6899, 0.8415]\n",
      "training end, used 134.90 s\n",
      "(0.004765982340961748, 0.7465753424657534, 0.6411764705882353, 0.689873417721519, 0.8415207304295764)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "2250 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00521, 0.7857, 0.4529, 0.5746, 0.8444]\n",
      "e_2 * test rst: [0.00548, 0.8451, 0.3529, 0.4979, 0.8433]\n",
      "e_3 * test rst: [0.00456, 0.7447, 0.6176, 0.6752, 0.8567]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00452, 0.7320, 0.6588, 0.6935, 0.8639]\n",
      "e_5 * test rst: [0.00464, 0.6784, 0.6824, 0.6804, 0.8541]\n",
      "e_6 * test rst: [0.00547, 0.7885, 0.4824, 0.5985, 0.8509]\n",
      "e_7 * test rst: [0.00468, 0.7361, 0.6235, 0.6752, 0.8636]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00478, 0.6410, 0.7353, 0.6849, 0.8682]\n",
      "e_9 * test rst: [0.00475, 0.6721, 0.7235, 0.6969, 0.8634]\n",
      "e_10 * test rst: [0.00491, 0.6758, 0.7235, 0.6989, 0.8633]\n",
      "e_11 * test rst: [0.00534, 0.6305, 0.7529, 0.6863, 0.8665]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00571, 0.5966, 0.8176, 0.6898, 0.8691]\n",
      "e_13 * test rst: [0.00595, 0.5772, 0.8353, 0.6827, 0.8675]\n",
      "e_14 * test rst: [0.00554, 0.6233, 0.7882, 0.6961, 0.8669]\n",
      "e_15 * test rst: [0.00528, 0.6256, 0.7765, 0.6929, 0.8710]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00468, 0.7233, 0.6765, 0.6991, 0.8683]\n",
      "e_17 * test rst: [0.00468, 0.7219, 0.6412, 0.6791, 0.8683]\n",
      "e_18 * test rst: [0.00465, 0.7296, 0.6824, 0.7052, 0.8689]\n",
      "training end, used 134.90 s\n",
      "(0.004649069090746012, 0.7295597484276729, 0.6823529411764706, 0.7051671732522795, 0.8688968717257896)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "2250 563\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00624, 0.8137, 0.4235, 0.5570, 0.8096]\n",
      "e_2 * test rst: [0.00524, 0.6718, 0.6684, 0.6701, 0.8419]\n",
      "e_3 * test rst: [0.00551, 0.7246, 0.5102, 0.5988, 0.8352]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00503, 0.6619, 0.7092, 0.6847, 0.8426]\n",
      "e_5 * test rst: [0.00524, 0.7126, 0.6327, 0.6703, 0.8449]\n",
      "e_6 * test rst: [0.00541, 0.6651, 0.7398, 0.7005, 0.8387]\n",
      "e_7 * test rst: [0.00518, 0.6383, 0.7653, 0.6961, 0.8424]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00528, 0.6943, 0.6837, 0.6889, 0.8442]\n",
      "e_9 * test rst: [0.00558, 0.7143, 0.6378, 0.6739, 0.8425]\n",
      "e_10 * test rst: [0.00567, 0.7161, 0.5663, 0.6325, 0.8402]\n",
      "e_11 * test rst: [0.00592, 0.7520, 0.4796, 0.5857, 0.8402]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00533, 0.6538, 0.7806, 0.7116, 0.8418]\n",
      "e_13 * test rst: [0.00548, 0.6511, 0.7806, 0.7100, 0.8403]\n",
      "e_14 * test rst: [0.00564, 0.6245, 0.7806, 0.6939, 0.8388]\n",
      "e_15 * test rst: [0.00599, 0.6015, 0.8010, 0.6871, 0.8370]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00598, 0.6070, 0.7959, 0.6887, 0.8367]\n",
      "e_17 * test rst: [0.00590, 0.6126, 0.7908, 0.6904, 0.8374]\n",
      "e_18 * test rst: [0.00576, 0.6220, 0.7806, 0.6923, 0.8392]\n",
      "training end, used 134.73 s\n",
      "(0.005758338827858174, 0.6219512195121951, 0.7806122448979592, 0.6923076923076923, 0.8392231552021354)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "2251 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00575, 0.8182, 0.3195, 0.4596, 0.7702]\n",
      "e_2 * test rst: [0.00616, 0.6074, 0.5858, 0.5964, 0.7727]\n",
      "e_3 * test rst: [0.00584, 0.7447, 0.4142, 0.5323, 0.7811]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00593, 0.7805, 0.3787, 0.5100, 0.7791]\n",
      "e_5 * test rst: [0.00548, 0.6667, 0.5444, 0.5993, 0.7874]\n",
      "e_6 * test rst: [0.00575, 0.6410, 0.5917, 0.6154, 0.7880]\n",
      "e_7 * test rst: [0.00575, 0.6452, 0.5917, 0.6173, 0.7990]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n",
      "e_8 * test rst: [0.00598, 0.5594, 0.6686, 0.6092, 0.7991]\n",
      "e_9 * test rst: [0.00575, 0.6447, 0.5799, 0.6106, 0.8011]\n",
      "e_10 * test rst: [0.00598, 0.7188, 0.5444, 0.6195, 0.7923]\n",
      "e_11 * test rst: [0.00606, 0.7431, 0.4793, 0.5827, 0.7944]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00588, 0.6250, 0.6213, 0.6231, 0.8008]\n",
      "e_13 * test rst: [0.00597, 0.6325, 0.6213, 0.6269, 0.8005]\n",
      "e_14 * test rst: [0.00605, 0.6287, 0.6213, 0.6250, 0.8009]\n",
      "e_15 * test rst: [0.00623, 0.6171, 0.6391, 0.6279, 0.8008]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00615, 0.6335, 0.6036, 0.6182, 0.8001]\n",
      "e_17 * test rst: [0.00613, 0.6369, 0.5917, 0.6135, 0.8010]\n",
      "e_18 * test rst: [0.00614, 0.6494, 0.5917, 0.6192, 0.8012]\n",
      "training end, used 134.34 s\n",
      "(0.006140521744073922, 0.6493506493506493, 0.591715976331361, 0.6191950464396285, 0.8012331180270111)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "2251 562\n",
      "init model\n",
      "training begin\n",
      "e_1 * test rst: [0.00466, 0.6581, 0.6182, 0.6375, 0.8245]\n",
      "e_2 * test rst: [0.00478, 0.7119, 0.5091, 0.5936, 0.8167]\n",
      "e_3 * test rst: [0.00443, 0.7206, 0.5939, 0.6512, 0.8509]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.00398, 0.7718, 0.6970, 0.7325, 0.8461]\n",
      "e_5 * test rst: [0.00440, 0.6630, 0.7394, 0.6991, 0.8287]\n",
      "e_6 * test rst: [0.00584, 0.5366, 0.8000, 0.6423, 0.8376]\n",
      "e_7 * test rst: [0.00425, 0.6739, 0.7515, 0.7106, 0.8499]\n",
      "Epoch     6: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch     6: reducing learning rate of group 1 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_8 * test rst: [0.00521, 0.5837, 0.7818, 0.6684, 0.8456]\n",
      "e_9 * test rst: [0.00594, 0.5344, 0.8000, 0.6408, 0.8429]\n",
      "e_10 * test rst: [0.00519, 0.5945, 0.7818, 0.6754, 0.8367]\n",
      "e_11 * test rst: [0.00452, 0.6703, 0.7515, 0.7086, 0.8360]\n",
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    10: reducing learning rate of group 1 to 1.2500e-04.\n",
      "e_12 * test rst: [0.00440, 0.6757, 0.7576, 0.7143, 0.8374]\n",
      "e_13 * test rst: [0.00452, 0.6720, 0.7697, 0.7175, 0.8384]\n",
      "e_14 * test rst: [0.00455, 0.6739, 0.7515, 0.7106, 0.8381]\n",
      "e_15 * test rst: [0.00459, 0.6798, 0.7333, 0.7055, 0.8380]\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    14: reducing learning rate of group 1 to 6.2500e-05.\n",
      "e_16 * test rst: [0.00434, 0.7375, 0.7152, 0.7262, 0.8358]\n",
      "e_17 * test rst: [0.00435, 0.7389, 0.7030, 0.7205, 0.8349]\n",
      "e_18 * test rst: [0.00441, 0.7405, 0.7091, 0.7245, 0.8348]\n",
      "training end, used 134.54 s\n",
      "(0.004412792878245332, 0.740506329113924, 0.7090909090909091, 0.7244582043343654, 0.8348370353408138)\n",
      "total label sum 184.5\n",
      "0.004765982340961748,0.7465753424657534,0.6411764705882353,0.689873417721519,0.8415207304295764\n",
      "0.004649069090746012,0.7295597484276729,0.6823529411764706,0.7051671732522795,0.8688968717257896\n",
      "0.005758338827858174,0.6219512195121951,0.7806122448979592,0.6923076923076923,0.8392231552021354\n",
      "0.006140521744073922,0.6493506493506493,0.591715976331361,0.6191950464396285,0.8012331180270111\n",
      "0.004412792878245332,0.740506329113924,0.7090909090909091,0.7244582043343654,0.8348370353408138\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.005145340976377038, 0.697588657774039, 0.680989708416987, 0.686200306811097, 0.8371421821450653]\n",
      "mlt train ended\n",
      "0.689455,0.683908,0.686671,0.822552\n"
     ]
    }
   ],
   "source": [
    "# all ann 1\n",
    "\n",
    "\n",
    "args.num_embedding = 64\n",
    "args.cnn_out_c = 100\n",
    "args.rnn_out_f_n = 68\n",
    "\n",
    "args.rnn_num_directions = 2\n",
    "args.rnn_layers = 2\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.3\n",
    "args.FC_dp = 0.1\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = False\n",
    "\n",
    "\n",
    "\n",
    "args.epochs = 18\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 1e-4\n",
    "args.max_grad_norm = 5.0\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "\n",
    "args.l2_weight_decay = 1e-4\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    train_dev_idx = train_dev_idx[:]\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv(tar_feature, train_dev_idx), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net(config).to(device)\n",
    "    model_init_w(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.0,\n",
      " 'FC_dp': 0.0,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 25,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 4,\n",
      " 'l2_weight_decay': 0,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 2,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 20,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 200,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 1,\n",
      " 'rnn_num_directions': 1,\n",
      " 'rnn_out_f_n': 100,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "init model\n",
      "Embedding(82949, 200, padding_idx=0)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "training begin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7480aebad84b8f975ced3d278e6c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4353.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e_1 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63b4c29da334756b3f1adf27f8d1741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=157.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev: 0.00885, 0.706, 0.733, 0.719, 0.917 *"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab24c3c59184bb8980a0047d8c9c31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=148.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test rst: [0.00801, 0.7928, 0.8438, 0.8175, 0.9520]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e7edd2be784b3d86af09fee5aaa2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4353.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e_2 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5872fd374c064751b9f81db9b6eeed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=157.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev: 0.00970, 0.743, 0.682, 0.711, 0.913 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82992949e0f4d9dbe83e8a1a6208a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=148.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test rst: [0.00818, 0.8271, 0.8154, 0.8212, 0.9506]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06a3b2495704518817dd1f5229d23ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4353.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e_3 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdd7e83ecf643f98d79ad717a4c9569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=157.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev: 0.01040, 0.694, 0.735, 0.714, 0.912 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c57423019c640988978e27791ddd255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=148.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test rst: [0.00859, 0.7837, 0.8341, 0.8081, 0.9506]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7ea8e1098b47178926816025f74c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4353.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e_4 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa298cb99b9404ca9b6139414c2d851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=157.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev: 0.01144, 0.707, 0.730, 0.718, 0.922 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8bb3109fe94a64af9de2bacb0e2327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=148.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test rst: [0.00962, 0.8059, 0.8438, 0.8244, 0.9543]\n",
      "saved checkpoint in ../models/abs_models/Ori_DisGeNet_abs.ckp\n",
      "training end, used 1666.61 s\n"
     ]
    }
   ],
   "source": [
    "# train on original model\n",
    "\n",
    "args.num_embedding = 200\n",
    "args.cnn_out_c = 25\n",
    "args.rnn_out_f_n = 100\n",
    "\n",
    "args.rnn_num_directions = 1\n",
    "args.rnn_layers = 1\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.0\n",
    "args.FC_dp = 0.0\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = True\n",
    "\n",
    "args.epochs = 4\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 0\n",
    "args.max_grad_norm = 20\n",
    "args.lr_reduce_factor = .5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 2\n",
    "args.use_loss_sh = True\n",
    "args.is_iterare_info = False\n",
    "args.l2_weight_decay = 0\n",
    "\n",
    "args.device = device\n",
    "\n",
    "args.modle_dir = '../models/abs_models'\n",
    "model_name_prefix = 'Ori_DisGeNet_abs'\n",
    "args.checkpoint_f = os.path.join(args.modle_dir, model_name_prefix + \".ckp\")\n",
    "args.config_save_f = os.path.join(args.modle_dir,  model_name_prefix + \".cf\")\n",
    "\n",
    "\n",
    "config = set_model_config(args)\n",
    "torch.save(config, args.config_save_f)\n",
    "\n",
    "model = Base_Net_Ori(config).to(device)\n",
    "model_init_w_ori(model)\n",
    "optimizer, scheduler = init_model_optimizer(model, args)\n",
    "\n",
    "train_dt, dev_dt, test_dt = tr_dataloader_rm, dev_dataloader_rm, dataloader_ori_t\n",
    "\n",
    "_ = train(model, optimizer, scheduler, train_dt, dev_dt, args, test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bff42943e64473858b754b213d5e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='evaluation', max=88.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0.028007570905773146, 0.6958174904942965, 0.6310344827586207, 0.6618444846292947, 0.8289799516093728)\n"
     ]
    }
   ],
   "source": [
    "args.modle_dir = '../models/abs_models'\n",
    "model_name_prefix = 'Ori_DisGeNet_abs'\n",
    "checkpoint_f = os.path.join(args.modle_dir, model_name_prefix + \".ckp\")\n",
    "config_save_f = os.path.join(args.modle_dir,  model_name_prefix + \".cf\")\n",
    "\n",
    "config = torch.load(config_save_f)\n",
    "# model, _, _ = load_checkpoint(config, checkpoint_f)\n",
    "model, optimizer, scheduler = load_checkpoint(config, checkpoint_f, Base_Net_Ori)\n",
    "\n",
    "config.device =  args.device\n",
    "\n",
    "args.is_iterare_info = False\n",
    "args.threshold = config.threshold \n",
    "args.l2_weight_decay = config.l2_weight_decay\n",
    "# model.update_model_config(config)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "pred_l, tru_l, S, pred_o = eval(model, dataloader_ann_1, args, 'test')\n",
    "_, _, _, f1, auc = S\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ----------------\n",
      "{'EB_dp': 0.0,\n",
      " 'FC_dp': 0.0,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'batch_size': 32,\n",
      " 'cnn_out_c': 25,\n",
      " 'device': device(type='cuda'),\n",
      " 'epochs': 8,\n",
      " 'l2_weight_decay': 0,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_cooldown': 10,\n",
      " 'lr_reduce_factor': 0.5,\n",
      " 'max_grad_norm': 20,\n",
      " 'max_token_n': 54,\n",
      " 'not_x_feature': False,\n",
      " 'num_embedding': 200,\n",
      " 'num_words': 82949,\n",
      " 'patience_epoch': 3,\n",
      " 'rnn_layers': 1,\n",
      " 'rnn_num_directions': 1,\n",
      " 'rnn_out_f_n': 100,\n",
      " 'threshold': 0.5,\n",
      " 'use_new_loss': False,\n",
      " 'warmup_epoch': 0,\n",
      " 'weight_decay': 0,\n",
      " 'window_sizes': [2, 3, 4, 5]}\n",
      "       ----------------\n",
      "cv, step 1\n",
      "4984 563\n",
      "init model\n",
      "Embedding(82949, 200, padding_idx=0)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "training begin\n",
      "e_1 * test rst: [0.01497, 0.6603, 0.6059, 0.6319, 0.8219]\n",
      "e_2 * test rst: [0.01502, 0.7500, 0.6882, 0.7178, 0.8578]\n",
      "e_3 * test rst: [0.01670, 0.6597, 0.7412, 0.6981, 0.8549]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.01726, 0.7342, 0.6824, 0.7073, 0.8515]\n",
      "e_5 * test rst: [0.02137, 0.7342, 0.6824, 0.7073, 0.8474]\n",
      "e_6 * test rst: [0.02530, 0.6117, 0.7412, 0.6702, 0.8480]\n",
      "e_7 * test rst: [0.02479, 0.6462, 0.7412, 0.6904, 0.8509]\n",
      "e_8 * test rst: [0.02595, 0.7289, 0.7118, 0.7202, 0.8502]\n",
      "training end, used 113.32 s\n",
      "(0.02595440800538283, 0.7289156626506024, 0.711764705882353, 0.7202380952380952, 0.8501870977398591)\n",
      "total label sum 197.5\n",
      "cv, step 2\n",
      "4984 563\n",
      "init model\n",
      "Embedding(82949, 200, padding_idx=0)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "training begin\n",
      "e_1 * test rst: [0.01496, 0.7333, 0.4529, 0.5600, 0.8346]\n",
      "e_2 * test rst: [0.01447, 0.6807, 0.6647, 0.6726, 0.8646]\n",
      "e_3 * test rst: [0.01470, 0.6802, 0.6882, 0.6842, 0.8634]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.01407, 0.7639, 0.6471, 0.7006, 0.8788]\n",
      "e_5 * test rst: [0.02034, 0.8000, 0.6118, 0.6933, 0.8714]\n",
      "e_6 * test rst: [0.01964, 0.7362, 0.7059, 0.7207, 0.8752]\n",
      "e_7 * test rst: [0.02142, 0.7255, 0.6529, 0.6873, 0.8705]\n",
      "e_8 * test rst: [0.02179, 0.6422, 0.7706, 0.7005, 0.8751]\n",
      "training end, used 113.02 s\n",
      "(0.021789751351409016, 0.6421568627450981, 0.7705882352941177, 0.7005347593582888, 0.8751234845083071)\n",
      "total label sum 186.5\n",
      "cv, step 3\n",
      "4984 563\n",
      "init model\n",
      "Embedding(82949, 200, padding_idx=0)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "training begin\n",
      "e_1 * test rst: [0.01567, 0.7305, 0.5255, 0.6113, 0.8170]\n",
      "e_2 * test rst: [0.01548, 0.6489, 0.7449, 0.6936, 0.8590]\n",
      "e_3 * test rst: [0.01537, 0.7414, 0.6582, 0.6973, 0.8602]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.01538, 0.7377, 0.6888, 0.7124, 0.8710]\n",
      "e_5 * test rst: [0.01827, 0.7500, 0.7194, 0.7344, 0.8777]\n",
      "e_6 * test rst: [0.02075, 0.7254, 0.7143, 0.7198, 0.8684]\n",
      "e_7 * test rst: [0.02040, 0.6792, 0.7347, 0.7059, 0.8663]\n",
      "e_8 * test rst: [0.02287, 0.6930, 0.7602, 0.7251, 0.8702]\n",
      "training end, used 116.04 s\n",
      "(0.022869113336447925, 0.6930232558139535, 0.7602040816326531, 0.7250608272506083, 0.8702107546015682)\n",
      "total label sum 219.0\n",
      "cv, step 4\n",
      "4985 562\n",
      "init model\n",
      "Embedding(82949, 200, padding_idx=0)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "training begin\n",
      "e_1 * test rst: [0.01688, 0.6102, 0.4260, 0.5017, 0.7638]\n",
      "e_2 * test rst: [0.02067, 0.5975, 0.5621, 0.5793, 0.7828]\n",
      "e_3 * test rst: [0.02186, 0.5445, 0.6154, 0.5778, 0.7907]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.02055, 0.6443, 0.5680, 0.6038, 0.8031]\n",
      "e_5 * test rst: [0.02778, 0.7500, 0.4793, 0.5848, 0.8001]\n",
      "e_6 * test rst: [0.02819, 0.7177, 0.5266, 0.6075, 0.8056]\n",
      "e_7 * test rst: [0.02952, 0.6644, 0.5740, 0.6159, 0.7949]\n",
      "e_8 * test rst: [0.02961, 0.6071, 0.6036, 0.6053, 0.7987]\n",
      "training end, used 116.90 s\n",
      "(0.029605821596982215, 0.6071428571428571, 0.6035502958579881, 0.6053412462908011, 0.7986810605718415)\n",
      "total label sum 188.0\n",
      "cv, step 5\n",
      "4985 562\n",
      "init model\n",
      "Embedding(82949, 200, padding_idx=0)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "training begin\n",
      "e_1 * test rst: [0.01524, 0.6853, 0.5939, 0.6364, 0.7978]\n",
      "e_2 * test rst: [0.01527, 0.6188, 0.6788, 0.6474, 0.8456]\n",
      "e_3 * test rst: [0.01584, 0.6561, 0.7515, 0.7006, 0.8617]\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 5.0000e-04.\n",
      "e_4 * test rst: [0.01440, 0.7413, 0.6424, 0.6883, 0.8788]\n",
      "e_5 * test rst: [0.02049, 0.7899, 0.5697, 0.6620, 0.8762]\n",
      "e_6 * test rst: [0.01999, 0.7812, 0.6061, 0.6826, 0.8791]\n",
      "e_7 * test rst: [0.02115, 0.7626, 0.6424, 0.6974, 0.8768]\n",
      "e_8 * test rst: [0.02020, 0.6667, 0.6909, 0.6786, 0.8795]\n",
      "training end, used 116.16 s\n",
      "(0.020197112630270554, 0.6666666666666666, 0.6909090909090909, 0.6785714285714286, 0.8795206472788337)\n",
      "total label sum 184.5\n",
      "0.02595440800538283,0.7289156626506024,0.711764705882353,0.7202380952380952,0.8501870977398591\n",
      "0.021789751351409016,0.6421568627450981,0.7705882352941177,0.7005347593582888,0.8751234845083071\n",
      "0.022869113336447925,0.6930232558139535,0.7602040816326531,0.7250608272506083,0.8702107546015682\n",
      "0.029605821596982215,0.6071428571428571,0.6035502958579881,0.6053412462908011,0.7986810605718415\n",
      "0.020197112630270554,0.6666666666666666,0.6909090909090909,0.6785714285714286,0.8795206472788337\n",
      "mean loss, prec, recall, f1, auc\n",
      "[0.024083241384098508, 0.6675810610038356, 0.7074032819152405, 0.6859492713418444, 0.854744608940082]\n",
      "mlt train ended\n",
      "0.667749,0.709195,0.687848,0.851868\n"
     ]
    }
   ],
   "source": [
    "args.num_embedding = 200\n",
    "args.cnn_out_c = 25\n",
    "args.rnn_out_f_n = 100\n",
    "\n",
    "args.rnn_num_directions = 1\n",
    "args.rnn_layers = 1\n",
    "args.window_sizes = [2, 3, 4, 5]\n",
    "args.EB_dp = 0.0\n",
    "args.FC_dp = 0.0\n",
    "\n",
    "args.use_new_loss = False\n",
    "args.use_cls_loss = True\n",
    "\n",
    "args.epochs = 8\n",
    "args.warmup_epoch = 0\n",
    "args.patience_epoch = 3\n",
    "\n",
    "args.learning_rate = 1e-3\n",
    "args.adam_epsilon = 1e-8\n",
    "args.weight_decay = 0\n",
    "args.max_grad_norm = 20\n",
    "args.lr_reduce_factor = 0.5\n",
    "args.threshold = .5\n",
    "args.lr_cooldown = 10\n",
    "args.use_loss_sh = False\n",
    "args.is_iterare_info = True\n",
    "args.l2_weight_decay = 0\n",
    "\n",
    "\n",
    "config = set_model_config(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "s_arr = []\n",
    "run_cls_df_l = []\n",
    "\n",
    "tar_feature = features_ann_1\n",
    "for idx, (train_dev_idx, test_idx) in enumerate(kf.split(tar_feature[1])):\n",
    "    cv_train_dev_ds, cv_test_ds = convert_features_to_dataset_cv_aug(tar_feature, train_dev_idx, features_ss_aug), \\\n",
    "                             convert_features_to_dataset_cv(tar_feature, test_idx)\n",
    "    \n",
    "    print('cv, step {}'.format(idx+1))\n",
    "    print(len(cv_train_dev_ds), len(cv_test_ds))\n",
    "    \n",
    "    train_dl = DataLoader(cv_train_dev_ds, batch_size=args.batch_size)\n",
    "    test_dl = DataLoader(cv_test_ds, batch_size=args.batch_size)\n",
    "\n",
    "\n",
    "    model = Base_Net_Ori(config).to(device)\n",
    "    model_init_w_ori(model)\n",
    "    optimizer, scheduler = init_model_optimizer(model, args)\n",
    "    _ = train(model, optimizer, scheduler, train_dl, None, args, test_dl, False)\n",
    "\n",
    "\n",
    "    #test\n",
    "    pred_l, tru_l, S, pre_o = eval(model, test_dl, args, 'test')\n",
    "    _, _, _, f1, auc = S\n",
    "    print(S)\n",
    "    \n",
    "    s_arr.append(list(S))\n",
    "    \n",
    "    y_info = tar_feature[1].iloc[test_idx].copy()\n",
    "    y_info['pred'] = pred_l\n",
    "    y_info['prob'] = pre_o\n",
    "    run_cls_df_l.append(y_info)\n",
    "    print('total label sum', sum(y_info.label))\n",
    "    \n",
    "mer_pd_rst = pd.concat(run_cls_df_l)\n",
    "s_arr = np.array(s_arr)\n",
    "\n",
    "for r in s_arr:\n",
    "    print(','.join([str(i) for i in r]))\n",
    "\n",
    "\n",
    "print('mean loss, prec, recall, f1, auc')\n",
    "print(list(np.mean(s_arr, axis=0)))\n",
    "print('mlt train ended')\n",
    "\n",
    "tru_l = mer_pd_rst['label'].to_numpy()\n",
    "tru_l[tru_l==.5] = 0\n",
    "pred_l = mer_pd_rst['pred'].to_numpy()\n",
    "pred_l[pred_l==.5] = 0\n",
    "pred_l = pred_l.astype(int)\n",
    "precision, recall, f1, _ = \\\n",
    "                    precision_recall_fscore_support(tru_l, pred_l, average='binary',zero_division=1)\n",
    "auc_s = roc_auc_score(mer_pd_rst['label'].to_numpy(), mer_pd_rst['prob'].to_numpy())\n",
    "print('%f,%f,%f,%f' % (precision, recall, f1, auc_s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _model_idx in range(10):\n",
    "#     args.num_embedding = 64\n",
    "#     args.cnn_out_c = 100\n",
    "#     args.rnn_out_f_n = 68\n",
    "\n",
    "#     args.rnn_num_directions = 2\n",
    "#     args.rnn_layers = 2\n",
    "#     args.window_sizes = [2, 3, 4, 5]\n",
    "#     args.EB_dp = 0.3\n",
    "#     args.FC_dp = 0.1\n",
    "\n",
    "#     args.use_new_loss = False\n",
    "#     args.use_cls_loss = False\n",
    "\n",
    "\n",
    "#     args.epochs = 20\n",
    "#     args.warmup_epoch = 0\n",
    "#     args.patience_epoch = 3\n",
    "\n",
    "#     args.learning_rate = 1e-3\n",
    "#     args.adam_epsilon = 1e-8\n",
    "#     args.weight_decay = 1e-4\n",
    "#     args.l2_weight_decay = 1e-4\n",
    "#     args.max_grad_norm = 5.0\n",
    "#     args.lr_reduce_factor = .5\n",
    "#     args.threshold = .5\n",
    "#     args.lr_cooldown = 2\n",
    "#     args.use_loss_sh = False\n",
    "#     args.is_iterare_info = True\n",
    "\n",
    "\n",
    "#     args.modle_dir = '../models/abs_models'\n",
    "#     model_name_prefix = 'Ann_abs'\n",
    "#     args.checkpoint_f = os.path.join(args.modle_dir, model_name_prefix + \".ckp\")\n",
    "#     args.config_save_f = os.path.join(args.modle_dir,  model_name_prefix + \".cf\")\n",
    "\n",
    "\n",
    "#     config = set_model_config(args)\n",
    "#     torch.save(config, args.config_save_f)\n",
    "\n",
    "#     model = Base_Net(config).to(device)\n",
    "#     model_init_w(model)\n",
    "#     optimizer, scheduler = init_model_optimizer(model, args)\n",
    "\n",
    "#     train_dt, dev_dt, test_dt = dataloader_merge, None, None\n",
    "\n",
    "#     _ = train(model, optimizer, scheduler, train_dt, dev_dt, args, test_dt, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading 1st data\n",
    "raw_data_dir = \"../data/ann_table/ann_1st.tsv\"\n",
    "s_df = pd.read_csv(raw_data_dir, sep='\\t', header=0)\n",
    "\n",
    "s_df['ann_label'] = \\\n",
    "s_df.apply(lambda x: 0.5 if (x['v2_class'] == 0) and  (x['Have -'] == '1') else x['v2_class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df1 = s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1, c2 = 'label', 'ann_label'\n",
    "nc1, nc2 = 'DisGeNet label', 'Annotated label'\n",
    "tar_s = s_df.groupby([c1, c2])[c2].size()\n",
    "tar_s.index = tar_s.index.rename([nc1, nc2])\n",
    "\n",
    "tar_s = tar_s.unstack(level=-1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,2)) \n",
    "ax = sn.heatmap(tar_s, cmap='Oranges', annot=True, fmt=\"d\", linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_label\n",
      "0.0    1732\n",
      "0.5     211\n",
      "1.0     870\n",
      "Name: ann_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f5a6449bfd0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(s_df.groupby(['ann_label'])['ann_label'].size())\n",
    "s_df.groupby(['ann_label'])['ann_label'].size().plot(kind='pie', subplots=True, startangle=90,\n",
    "figsize=(5,5), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading 2nd data\n",
    "raw_data_dir = \"../data/ann_table/ann_2nd.tsv\"\n",
    "s_df = pd.read_csv(raw_data_dir, sep='\\t', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df['new_label'] = 0.\n",
    "s_df.loc[pd.isna(s_df['r1_label']), 'new_label'] = s_df[pd.isna(s_df['r1_label'])]['label']\n",
    "s_df.loc[~pd.isna(s_df['r1_label']), 'new_label'] = s_df[~pd.isna(s_df['r1_label'])]['r1_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df['ann_label'] = \\\n",
    "s_df.apply(lambda x: 0.5 if (x['new_label'] == 0) and  (x['Have -'] == '1') else x['new_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAACaCAYAAADYQpFXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAaoElEQVR4nO3de7xVc/7H8dd771PpqvtFpZuiy1RmMi6F3CIkZBBNSSN+g340TaFB+OUyP4bBT4pCiFBNIbkUch2UrpQixlG6X+h07/P7Y61Tp2OffXZH5+y9z/48H4/1OGt913et9Tmr+vT9rst3ycxwzrlMFEl2AM45lyyeAJ1zGcsToHMuY3kCdM5lLE+AzrmM5QnQOZexspIdQBz+fI5zyaGibDTsiDIx/80OW7SjSPsrCamcABl2RJlkh5Dyhi3aATlrkh1G6qtQEwD7cV6SA0l9qtu2SNtFUjbNFSylE6BzLn1EPQE65zKVtwCdcxkryxOgcy5TeQvQOZex/Bqgcy5jZUXS78k1T4DOuQMiHd+q8ATonDsgstIwA3oCdM4dEH4TxDmXsfwmiHMuY6VjAkzDXrtzLhVFFXsqjKQxklZJWpCnbJikHyTNCacz86y7UdJSSYslnZ6n/IywbKmkGxKJ2ROgc+6AiCj2lIAngTNilN9vZu3DaSqApFbAxUDrcJtHJEUlRYH/A7oCrYCeYd24vAvsnDsgyhSxOWVmMyU1TrB6d+B5M9sGLJO0FPh9uG6pmX0DIOn5sO4X8XbmLUDn3AFR1C5wHNdImhd2kauFZfWB7/PUyQ7LCiqPyxOgc+6AKCgBSuov6bM8U/8EdjcCaAa0B1YA94XlsVKqxSmPy7vAzrkDokwBr8KZ2Shg1P7sy8xW5s5Legx4JVzMBhrmqdoAWB7OF1ReoAIToKSXiZNBzeycwnbunMscB/IxGEn1zGxFuHgekHuHeAowTtI/gEOA5sAnBC3A5pKaAD8Q3Ci5pLDjxGsB3lvE2J1zGaio4wFKeg7oDNSUlA3cCnSW1J6gEfYtcCWAmS2U9ALBzY2dwNVmtivczzXA60AUGGNmCwuNuaAVZvZungDLA4ea2eKi/ILOudKvqO8Cm1nPGMWj49QfDgyPUT4VmLo/xy70GqCkbgStwbJAkzAr315ausDdhz9Gi85nsnntKh4550gALvjHs9RscjgAB1U5mK2bNvLoeR0AqNPiN5x9+yOUq1gZM+OxC45h5/ZtXDb2LSrVqsvOrVsBeLpfVzavW52cX6oErfhxJYNvvoM1a9cRkbiwR3f6XHIhAE8/9yLPjJ9AVjTKiccfx+Drrk5ytCVrxao1DBn+MGvWbSASERd2O5XeF5zF30eM5e0PZ1EmK4tDD6nDnTdcTZXKFQEY+cwkJkydTiQSYeiAyzn+9+2T/FskrrSOCD2M4DmbdwDMbM5+PLOT8uZMeopPnn2E8+4es6fspYGX7pnvMuTvbPtpIwCRaJTz//cpJg6+jJWL51G+anV27dyxp+7Ev/Zh+YJZJRd8CohGo9ww8Fpatzycnzdvpscl/eh49FGsWbeO6e+8z8svjKVs2bKsXbc+2aGWuGg0ypCre9O6RVN+ztlCjyuGcFyHthzXoR0Dr7iUrKwo9z76DKOencSgq3qx9NvvmTrjA1558n5WrV1H34F3MO2ZfxKNRpP9qySktL4Kt9PMNhZ7JEny3Wfvs2XjugLXtz7jAua/Oh6AZh1PY+Xi+axcHHxaccuGddju3SUSZ6qqXasmrVsGreVKFSvStEkjVq5ezXMv/ov+fXtRtmxZAGpUrxZvN6VS7RrVaN2iKQCVKpSnWaP6rFy9jk5HtSMrK0hq7Vo158fVawGY/v5nnHlyR8qWLUODenU4tH5d5n25NGnx768yEYs5pbJEEuACSZcAUUnNJT0EfFjYRpKOkDRE0oOS/hnOt/zVEZegRh06sXntKtZ9F/wlrNG4BWZGr8df5coJn9Cx31/2qd/9zse5atJnnPBfNyUj3KTLXr6CLxcvoV2b1nz73X/47PO5/OGPV9Cr39XMW/hlssNLquwVq/hyyTLatWq+T/mEqW9zwtHBpZeVa9ZSr3aNPevq1qrOyjUF/+ecaorhQehil0gCvJbgvbttwHPAJuC6eBtIGgI8T3Br+hPg03D+uURfUk4Fbc66mPmvPr9nOZIV5dDfHcfEQb0Zc+mJHHHauTQ55iQAJgzqzYhzjmRMr8406tCJdt17JSvspNick8OAQUO5adAAKlWqyK5du9i06SdeGDuKwddfzXWDb8YstVsDxWVzzhYG3HIvN17bl0oVK+wpf/TpCWRFI3Q77figIMbpkVI8g+RRRrGnVFboNUAzywGGSronWLSfEthvP6C1me3IWxg+u7MQuDvWRuET4v0BRo4cmcBhik8kGqXlaecyqsfRe8o2/fgD3336Hjkbgi7Lkndfo16rI1n28dv8tCp45nL75p+Z/8rz1G97FHMnP5OU2Evajh07GTBoKN26dqHLKZ0BqFOnNqedciKSaNumFZGIWL9+A9UzrCu8Y+dOBtxyH91OPZ4uJ+z9uzRp2ju8/eEsnrz/1j1Jrk6tGqxYtXZPnR9Xr6N2jfQ5X9E0fK+s0JAlHSVpPjAPmC9prqTfFbLZboKHFPOrF66LycxGmVkHM+vQv38ib8sUn6bHnsKaZYvZtPKHPWVL33+DOi1+Q5mDyhOJRml81Ams/vpLItEoFaoGXZdIVhYtOp/Jqq8KfQSpVDAzht52F02bNKLvHy/eU35q5+P5+JPghtCy7/7Djh07qVatarLCTAoz42/3jKBZo/r0vajbnvL3/v05j4/7FyPuGkL5g8rtKT+5YwemzviA7dt3kL1iJd9lr6Bty8OSEXqRRKSYUypL5C7waODPZvYegKROwBNA2zjbXAdMl7SEvS8oHwocBlxT9HAPvB73PU3jo06kQrWaDHxnGW8/dDufT3iCNmddxIJXxu9Td+umDXz05ANc8eJHYMaSmdNY8u5rlClfgV6jpxLNKoMiEb75aAazXnw8Sb9RyZo1Zx6TX51Gi+bN6H5RHwAGXnMlPc49m5uG3cnZF/SiTJky3H3739KqO3cgzJ6/iMlvzKRF00M5t98gAK6/4hKGPziG7dt3cvlf7gCgXasW3PaX/jRv0pCuJx3LWX2uJxqNcMt1f0qbO8AAkVS/4BeDCrsuI+kDM+tYWFmM7SIEj8/UJ7j+lw18mvvUdgJs2BFlEqyauYYt2gE5a5IdRuqrUBMA+3FekgNJfarbtkiZbFn3sjGTSZPJ21M2M8Z7F/i34ewnkkYS3AAx4CLCZwLjMbPdwMcHIEbnXBpQGrYA43WB78u3fGue+cy8neecK1A6doHjvQt8UkkG4pxLb5E0/C5mQuMBSjqL4FnAg3LLzOz24grKOZd+FEm/52ASGQzhUaACcBLwOHABwcPNzjm3RzQNu8CJpOzjzKw3sN7MbgOOZd+RV51zDkUUc0pliXSBt4Q/cyQdAqwFmhRfSM65dBQpjV1g4BVJVYH/BWYT3AHOjKd8nXMJK1V3gXOZ2R3h7ARJrwAHlebhsZxzRVOq7gJLOj/OOsxsYvGE5JxLR5E0HA0hXguwW5x1BngCdM7tkeo3PGKJ9yB035IMxDmX3pRGAzfk8g+jO+cOCEXTL52kX6fdOZeSFInEnArdThojaZWkBXnKqkt6U9KS8Ge1sFzhZzaWSpqXZ9AWJPUJ6y+R1CeRmBMZELVcImXOucymaDTmlIAngTPyld0ATDez5sD0cBmgK9A8nPoDIyBImAQDthxNMAzfrblJM55EWoAfJVjmnMtgimbFnApjZjOB/F9/6g48Fc4/BZybp3ysBT4GqkqqB5wOvGlm68xsPfAmv0yqvxDvMZi6BIOZlpd0JMGgpgBVCN4Nds65vQ7smyB1zGwFgJmtkFQ7LK/P3lHmIRhouX6c8rjipefTgcuABsA/8pRvAjLzu4/OuQIpEru7m/djZ6FRZjaqqIeJUWZxyuOK9xjMU8BTknqY2YTE43POZSJlxU4nYbLb34S3UlK9sPVXD1gVlmez72AsDYDlYXnnfOXvFHaQRNqsH0gaLek1AEmtJPVLYDvnXAYp6l3gAkwBcu/k9gEm5ynvHd4NPgbYGHaVXwe6SKoW3vzoEpbFlUh0T4Q7yv3M5VcU8mF051zmUSQacyp0O+k5ghurh0vKDhtYdwOnhV+WPI293xKfCnwDLAUeA/4MYGbrgDuAT8Pp9rAsrkSeXKxpZi9IujE80E5JiX7ZzTmXIQrqAhfGzHoWsOqUGHUNuLqA/YwBxuzPsROJeLOkGoQXFHObnftzEOdc6Vcqh8QHBhL0u5tJ+gCoRTAsfrEbtmhHSRwm/YXfvHWFU922yQ6h9Eqgu5tqEhkPcLakE4HDCW41LzazkslMm7JL5DBprUoD/zB6IsL/JHZPG5rkQFJf5IzhRdquqF3gZIr3IPQJBaw6NhwPcGYxxeScS0elrAX41xhlBrQjeMYm/X5b51zxiZZJdgT7Ld6D0PsMiCqpEzAUWAFcU8xxOefSTSlrAQIg6RTgZoLW351m9maxR+WcSz+l6S6wpLMIWnwbgaFm9kGJReWcSz+lqQsMvEzwft1aYIi077vGZnZOMcblnEs3pawLfFKJReGcS3+lKQGa2bu585LKA4ea2eISico5l35K4zdBJHUD5gDTwuX2kqYUd2DOuTQTicaeUlgit22GEYyxvwHAzOYAjYsvJOdcWkrDBJhIm3WnmW3MfxPEOef2UcruAudaIOkSICqpOTAA+LB4w3LOpZ1o+j0HmEjE1wKtgW3AcwTfBPEBUZ1z+yqNXWAzyyF4INqH0XDOFSxaNtkR7LcCW4CSOknqnWf5JUkzwunkkgnPOZc2SlkL8DaC7m+uwwk+k1mR4LOYM4ovLOdc2knxZBdLvGuAVczsizzLS8xsVjgOYOVijss5l26iZWNPKSxeC7Bq3gUzOz/PYp3iCcc5l7ZKWQtwUTgizD4knQ34K3HOuX1llYk9pbB4LcDrgVclXQDMDst+BxwHnF3cgTnn0kyk6O8CS/oW+AnYRfDyRQdJ1YHxBG+efQtcaGbrFbyV8U/gTCAHuMzMZsfab6EhF7TCzJYCbYH3wgAaAzOBtmb2VVEO5pwrxX79XeCTzKy9mXUIl28ApptZc2B6uAzQFWgeTv2BEUUNOW7KNrNtksYDW81sl6QWQBdJr5XYl+GS6MlxL/Hiv6YiiRaHNeGuWwYze+4C/v7gSHbvNipUKM/dtw6mUcP6yQ41aVb8uJLBN9/BmrXriEhc2KM7fS65kNfenMHDj47m62Xf8eLTj/Gb1i2THWpSbMrZzs3Pz2LJik1I8D89O7BywxYenvYF36zcxAsDT6bNodX32Wb5uhy63fU6V3dtxeUnH56kyIvgwL8K1x3oHM4/BbwDDAnLx4YfSf9YUlVJ9cxsxf4eIJE3QWYC5STVJ8jCfYEn9/dA6WblqtWMHT+JCWNH8Mr40ezavZtX35jBsHse4N47bmLyuFGcffrJjBj9TLJDTapoNMoNA6/ltYnjGD92FOPGT2Tp18to0awpD913J0f9tn2yQ0yqOyfOpVPLukwdejqTBp9GszqVaV6vCg9dfiwdmsX+nvPdk+ZyfKu6JRzpARDJij0lxoA3JM2S1D8sq5Ob1MKftcPy+sD3ebbNDsv2WyLRycxyJPUDHjKzv0v6vCgHSze7du5i67ZtZGVlsXXrVmrXqgmInzfnAPDzz5upXatGcoNMstq1aobnBSpVrEjTJo1YuXo1HY/5fZIjS76ft+7gs69Xc9elQY+ubFaEslllqVKh4EdD3pr3Aw1rVqR82fS7o1pQdzdMaP3zFI0ys1H5qnU0s+WSagNvSloU50ixRmax/Yo1lFAClHQscCnQbz+2K2hnfc3siaJuX1Lq1K7F5b3+wEndelKuXDk6Ht2BTsd0YPjf/kL/626kXLlyVKpYgRfGPJzsUFNG9vIVfLl4Ce3atE52KCnh+zWbqV6pHDeN+4zFP2ykVcOq3HR+eyqUi/3PJ2fbTh6fvpjRfz6BJ2ak4YMWBdzxDZNd/oSXv87y8OcqSZMIhuBbmdu1lVQPWBVWzwYa5tm8AbC8KCEn0gW+DrgRmGRmCyU1Bd4uysFCt/2KbUvMxk0/MX3mh0yf/CzvvfYCW7ZuYfLUN3ly3ARGPXAXM18dz/ndzuCuB4p8/bVU2ZyTw4BBQ7lp0AAqVaqY7HBSwq7du/kiewMXd2zKxMGnUqFsFo+9VXDD5uHXFtKnc3MqFpAgU14Ru8CSKkqqnDsPdAEWAFOAPmG1PsDkcH4K0FuBY4CNRbn+B4kNhvAu8G6e5W8IhsQqkKR5Ba0izkPUeZvKI0eOpP/FZxYWXrH58JPZNDikLtWrBc+DdznpeGbPW8iiJV/Trk1wQf/M0zrzpwE3xNtNRtixYycDBg2lW9cudDmlc7LDSRl1qlagTtXytGscXCbp0r4+j71VcMtu3nfreH3uD9w7ZT4/bdlBRFAuK8qlJxxWUiH/OkV/ELoOMCkcczQLGGdm0yR9CrwQXn77D/CHsP5UgkdglhI8BtO3qAeO91nMB8zsOkkvE6N/XchX4eoApwPr8++WOGMJ5msqG5uy4xyieB1StzZz53/Jlq1bOahcOT76dDZtWh7OtLfeZdl339OkUUM++PcsmjVulLQYU4GZMfS2u2japBF9/3hxssNJKbWqHES9quVZtvInmtSpzMdfreKwulUKrP/Mf+/9DtnDry2kQrms9El+UOTnAMNGVbsY5WuBU2KUG3B1kQ6WT7yInw5/3luE/b4CVAqHz9+HpHeKsL8S165NS04/5QTO63UVWdEoLQ8/jIvOO4u6tWsxYMhtKCIOrlyZO28elOxQk2rWnHlMfnUaLZo3o/tFQW9l4DVXsn3HDu64537Wrd/AlQP+SsvDmzP6kfuTHG3JG9rjSP769Cfs2LmbhjUrMvySDrw59weGT5jDup+3cdXIDziiQVUe/6/jkx3qr6f0u3GjIJkWUkmqBWBmq4s9or2S2gJMG1UaQM6aZEeR+ioEd6p3T/NhLQsTOWN4kb5/sfuLiTGTSaTV+Sn7PY144wFK0jBJa4BFwFeSVku6peTCc86ljV/3HGBSxLsLfB3QETjKzGqYWTXgaKCjpOtLJDrnXPpIwwFR4yXA3kBPM1uWWxBerOwVrnPOub3SsAUYL7oyZvaLi0tmtlpSao9x45wrcUrDmyDxEuD2Iq5zzmWiSPp9FjNeAmwnaVOMcgEHFVM8zrl0leLd3VgKjNjM0q8965xLnlLWBXbOucR5AnTOZaxo+qWT9IvYOZeavAXonMtYKl13gZ1zLnGeAJ1zGcsToHMuY3kCdM5lrBQf+CAWT4DOuQPDW4DOucyVsuOeFsgToHPugJB3gZ1zGcu7wM65jOVvgjjnMpa3AJ1zGUvpdxMkoc9iJknKBuZcKVe0TJazOva/2Qq1UjYzpnICTDmS+pvZqGTHkQ78XCXGz1NypV+nPbn6JzuANOLnKjF+npLIE6BzLmN5AnTOZSxPgPvHr9Ukzs9VYvw8JZHfBHHOZSxvATrnMpYnwBgknSFpsaSlkm6Isb6cpPHh+n9LalzyUSZfAufpMkmrJc0Jpz8lI85kkzRG0ipJCwpYL0kPhudxnqTflnSMmcoTYD6SosD/AV2BVkBPSa3yVesHrDezw4D7gXtKNsrkS/A8AYw3s/bh9HiJBpk6ngTOiLO+K9A8nPoDI0ogJocnwFh+Dyw1s2/MbDvwPNA9X53uwFPh/EvAKVIavgf06yRynhxgZjOBdXGqdAfGWuBjoKqkeiUTXWbzBPhL9YHv8yxnh2Ux65jZTmAjUKNEoksdiZwngB5ht+4lSQ1LJrS0k+i5dAeYJ8BfitWSy3+rPJE6pV0i5+BloLGZtQXeYm+r2e3L/z4liSfAX8oG8rZUGgDLC6ojKQs4mPhdnNKo0PNkZmvNbFu4+BjwuxKKLd0k8nfOFQNPgL/0KdBcUhNJZYGLgSn56kwB+oTzFwAzLPMeqCz0POW7jnUO8GUJxpdOpgC9w7vBxwAbzWxFsoPKBD4eYD5mtlPSNcDrQBQYY2YLJd0OfGZmU4DRwNOSlhK0/C5OXsTJkeB5GiDpHGAnwXm6LGkBJ5Gk54DOQE1J2cCtQBkAM3sUmAqcCSwFcoC+yYk08/ibIM65jOVdYOdcxvIE6JzLWJ4AnXMZyxOgcy5jeQJ0zmUsT4BpTtJ5kkzSEcW0/86SjjtQ9WJs962kmomW56vz834ea5ikQfsboyu9PAGmv57A+xTfs4idgUQSW6L1nEsZngDTmKRKQEeC4bkuzlPeWdI74QAEiyQ9mztaTdiyuk3SbEnzc1uOkqpL+lc4cMHHktqG4xxeBVwfjud3vKRu4RiIn0t6S1KdAurVkjRB0qfh1DE8Tg1Jb4TbjySBb9CGcc2StFBS/3zr7gt/l+mSaoVlzSRNC7d5r7hax64UMDOf0nQCegGjw/kPgd+G850JRqhpQPCf3EdAp3Ddt8C14fyfgcfD+YeAW8P5k4E54fwwYFCeY1Zj7wP0fwLuK6DeuDzHPBT4Mpx/ELglnD+L4KX/mjF+t29zy4Hq4c/ywAKgRrhswKXh/C3Aw+H8dKB5OH80wauKv4jRJ5/8Vbj01hN4IJx/PlyeHS5/YmbZAJLmAI0JusoAE8Ofs4Dzw/lOQA8AM5sRttQOjnHMBsD48D3fssCyAmI7FWiVZ5jEKpIqAyfkHtPMXpW0PoHfc4Ck88L5hgQDh64FdgPjw/JngIlhq/g44MU8xy6XwDFcBvIEmKYk1SBoqbWRZATv45qkwWGVbXmq72LfP+ttMcoTHZLpIeAfZjZFUmeCVlUsEeBYM9uSL+6C9htTeIxTw33lSHoHOKiA6hYed4OZtU/0GC5z+TXA9HUBwSjCjcyssZk1JGiNdSri/mYCl8KepLPGzDYBPwGV89Q7GPghnO+Tpzx/vTeAa3IXJOUmpLzH6UrQpY7nYILPD+SE1/KOybMuQnAeAC4B3g9jXibpD+ExJKldIcdwGcoTYPrqCUzKVzaBIBEUxTCgg6R5wN3sTW4vA+fl3twI670o6T1gTZ7t89cbkLs/SV8Q3CQBuA04QdJsoAvwn0LimgZkhXHdAXycZ91moLWkWQSt4dvD8kuBfpLmAgvxofpdAXw0GOdcxvIWoHMuY3kCdM5lLE+AzrmM5QnQOZexPAE65zKWJ0DnXMbyBOicy1ieAJ1zGev/ARZY23Nhj6RUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1, c2 = 'label', 'ann_label'\n",
    "nc1, nc2 = 'DisGeNet label', 'Annotated label'\n",
    "tar_s = s_df.groupby([c1, c2])[c2].size()\n",
    "tar_s.index = tar_s.index.rename([nc1, nc2])\n",
    "\n",
    "tar_s = tar_s.unstack(level=-1)\n",
    "fig, ax = plt.subplots(figsize=(5,2)) \n",
    "# tar_s = tar_s.transpose()\n",
    "ax = sn.heatmap(tar_s, cmap='Oranges', annot=True, fmt=\"d\", linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_label\n",
      "0.0    1853\n",
      "0.5      47\n",
      "1.0     834\n",
      "Name: ann_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5a64883e50>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(s_df.groupby(['ann_label'])['ann_label'].size())\n",
    "s_df.groupby(['ann_label'])['ann_label'].size().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2, n3 = 'positivel', 'ambiguous', 'negative'\n",
    "\n",
    "tar_s1 = s_df1.groupby(['ann_label'])['ann_label'].size()\n",
    "tar_s1 = tar_s1.rename(index={1: n1, 0.5:n2, 0: n3})\n",
    "tar_s1 = tar_s1.to_frame()\n",
    "tar_s1 = tar_s1.rename_axis(None)\n",
    "tar_s1 = tar_s1.rename(columns={'ann_label': '1st annotated abstract dataset'})\n",
    "\n",
    "# del tar_s1.index.name\n",
    "\n",
    "tar_s = s_df.groupby(['ann_label'])['ann_label'].size()\n",
    "tar_s = tar_s.rename(index={1: n1, 0.5:n2, 0: n3})\n",
    "tar_s = tar_s.to_frame()\n",
    "tar_s = tar_s.rename_axis(None)\n",
    "tar_s = tar_s.rename(columns={'ann_label': '2nd annotated abstract dataset'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_s = tar_s1.merge(tar_s, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st annotated abstract dataset</th>\n",
       "      <th>2nd annotated abstract dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1732</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambiguous</th>\n",
       "      <td>211</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positivel</th>\n",
       "      <td>870</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1st annotated abstract dataset  2nd annotated abstract dataset\n",
       "negative                             1732                            1853\n",
       "ambiguous                             211                              47\n",
       "positivel                             870                             834"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mer_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mer_s.plot.pie(subplots=True, figsize=(12, 6), startangle=0,  autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           1st annotated abstract dataset\n",
       " negative                             1732\n",
       " ambiguous                             211\n",
       " positivel                             870,\n",
       "            2nd annotated abstract dataset\n",
       " negative                             1853\n",
       " ambiguous                              47\n",
       " positivel                             834)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_s1, tar_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/bal31/jhsu/home/anaconda3/envs/venv/lib/python3.7/site-packages/matplotlib/text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = {'Yes':pd.Series([825, 56], index=[\"Total\", \"Last 2 Month\"]), 'No':pd.Series([725, 73], index=[\"Total\", \"Last 2 Month\"])}\n",
    "df = pd.DataFrame(d)\n",
    "df = df.T\n",
    "def absolute_value(val):\n",
    "    a  = np.round(val/100.*df.values, 0)\n",
    "    return a\n",
    "\n",
    "df.plot.pie(subplots=True, figsize=(12, 6),autopct=absolute_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Last 2 Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>825</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>725</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total  Last 2 Month\n",
       "Yes    825            56\n",
       "No     725            73"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00b6a19122454087be2679522fa6f268": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_67a3c39002e54a7eb807216e0e6c7a3e",
        "IPY_MODEL_b157317f82b343a3a7f12696b764b88d"
       ],
       "layout": "IPY_MODEL_e439ca65dee24359a000a505ed41a480"
      }
     },
     "07e05f82a76149c6aef1fdb2b608388a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "08211dc7247c4ff5ac7dcdd7aea20e2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "0875182a1b4747d2aa00f5d9152b655f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "08e51381a31f428cab096054e747f71f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1fc51c75b58a409f8832651aa2f4818e",
        "IPY_MODEL_f988f4156b17413290924e4464703cb1"
       ],
       "layout": "IPY_MODEL_bdd547e134c04deb910d4bba67c985c2"
      }
     },
     "097644bf303f42ba8cb98cbf57eff30e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "09f4d332b91f46229b81ffd0a64326db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "0a236c04424d4beebc8550b66d70a604": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "0b031c8a89924c1caecc82edb9475327": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_79ace6c1f33d46db921692184459eb28",
        "IPY_MODEL_5bac2cb1977744eda283d07d3f9a49f2"
       ],
       "layout": "IPY_MODEL_835b4db9434a468facdc052491b44170"
      }
     },
     "0ca5c7c74ea0414c94c86945493c81ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.00252, 0.927, 0.904, 0.915,  0.978/ BF 0.915} : 100%",
       "layout": "IPY_MODEL_bc386895a30844329164a7dbf0783263",
       "max": 4353,
       "style": "IPY_MODEL_0fd6e2eccf5646b3a785ec6fd2c96d7b",
       "value": 4353
      }
     },
     "0fd6e2eccf5646b3a785ec6fd2c96d7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "1023fc59857d47b1bf9025273ad3b13c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "11fe27ce89cc4043959abd8cf5e6b713": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "14f0e17827ae4efc90933ea1bdd4457c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.17114, 0.665, 0.535, 0.593,  0.802/ BF 0.593} : 100%",
       "layout": "IPY_MODEL_7338072c8dc44303a7bfcbffae21a9bb",
       "max": 174,
       "style": "IPY_MODEL_a60b3bf1a0f0439ca3759ea1d2c045ed",
       "value": 174
      }
     },
     "163c863266254898a76b67c105adfd10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_78480c07ab904c448fe5888b3432c839",
        "IPY_MODEL_ee14c53b32cf4662806cdbf976869636"
       ],
       "layout": "IPY_MODEL_f8e9ec2e9f5d463da62eddad475cabba"
      }
     },
     "18975cb9da8b4a66b26a558ada57eb10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "1aabb28858544509b422938b3b06c474": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "1e2c414a8b3240c3b232f7cb9f135d64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "1e75918cf10f4cfdb71b3e33a476457e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "1fc51c75b58a409f8832651aa2f4818e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.00829, 0.871, 0.821, 0.845,  0.955/ BF 0.847} : 100%",
       "layout": "IPY_MODEL_2d3784c023ca4072a68dec782edd6840",
       "max": 4353,
       "style": "IPY_MODEL_d7cc5c9306ed43f696f31e7d7efc6d9a",
       "value": 4353
      }
     },
     "23222f0b5fe74fd1ae56c0adad692bb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "It { L 0.02153, 0.884, 0.959, 0.920,  0.966/ BF 0.927} :  41%",
       "layout": "IPY_MODEL_62520786ba34495998782320bf66f8f3",
       "max": 174,
       "style": "IPY_MODEL_11fe27ce89cc4043959abd8cf5e6b713",
       "value": 72
      }
     },
     "247aa67b0d524ce591f032e43089dca4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "26f547733c0c469d8cff89e810b297d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_23222f0b5fe74fd1ae56c0adad692bb8",
        "IPY_MODEL_ed9e400772c643aa9f8410064a2b7c28"
       ],
       "layout": "IPY_MODEL_990759c2ffbd433f93934326e545a52e"
      }
     },
     "2830f753715b42a5a58bad02c53eaf60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.01268, 0.868, 0.819, 0.843,  0.956/ BF 0.845} : 100%",
       "layout": "IPY_MODEL_bdf2a6a235574886a49b75a027e57414",
       "max": 4353,
       "style": "IPY_MODEL_c5c72d85dcd049cc85e503ed5da2e933",
       "value": 4353
      }
     },
     "2af8fc86a5f64e71876a0789ce32e184": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "2ba6113093174861b6325a0d8c8ffb53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2c6247b18d654affb989d2053958ca1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "2d3784c023ca4072a68dec782edd6840": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "3065dc8950b74b4b984b66a703c0f02d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_14f0e17827ae4efc90933ea1bdd4457c",
        "IPY_MODEL_b6d3a62e47c24bb5a54198b51f6ad1f0"
       ],
       "layout": "IPY_MODEL_eb7e38089e7b4914913927da6b0847a6"
      }
     },
     "32727aeae87f4dc5b18580c3de79fb30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_999209b5ce9e4445a1c5703544d40a9d",
       "style": "IPY_MODEL_1023fc59857d47b1bf9025273ad3b13c",
       "value": " 4353/4353 [22:57&lt;00:00,  3.16it/s]"
      }
     },
     "333e1942561641b2acb241acbf0063fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "334c6b14a9d3477c805707ff58c1a8e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "34ccbf88aa5542b68da5ff76a5c7c274": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "352e7c65ac0b487c9b1ceae9dd2cdd30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "3924debf12d3457794903e64d9a182b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fa076cd196b34fdcafcac2d9110ec12e",
        "IPY_MODEL_9b5507391f684217a8a859ca9eed3e34"
       ],
       "layout": "IPY_MODEL_1e75918cf10f4cfdb71b3e33a476457e"
      }
     },
     "39c695f951e140a4bb61f4e503fc35de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a59adf3c26447e89fceaee696ae7fab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3d6dd986de964880925afe9af62dbf28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3e8d5adc640244aa9cba6d0a57a9f742": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "400eeae29a70417189bdb3b861bf275b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "40fed54cde3c4054aff1f86e0097a003": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4704debba3574352888100dcf3a0fda4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_abf5ba7cbe574e2e8638e531bc7303f7",
        "IPY_MODEL_d2b371608d444db88dcf65840bfad964"
       ],
       "layout": "IPY_MODEL_f4b040a930b44e699f22be5c05ff6d42"
      }
     },
     "4825005b81e049bdb5b5fa385d1f1543": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_81f2a85f942b428a8cb97f3a4aaa2799",
       "style": "IPY_MODEL_cc24e45743f147fcb177e2eb2680e4aa",
       "value": " 174/174 [00:13&lt;00:00, 13.35it/s]"
      }
     },
     "49273e5401a34509914842dfc87c217d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.02530, 0.816, 0.724, 0.767,  0.920/ BF 0.767} : 100%",
       "layout": "IPY_MODEL_f4758f51c0cc4a4fa8289405657f4498",
       "max": 4353,
       "style": "IPY_MODEL_fb2ffabe3d2e4c0cb5e8ce128d3cbbc7",
       "value": 4353
      }
     },
     "4bdcd0bde26d440e9357fa93c1603392": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4cc47e2021224d65bead9a91ebab69c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "4f8407b099ae4fc7a6368fabe730f51a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "503ba4e658b140c3acc246c48017a6e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "523573c6f65a43eea83ff94dcb6ded30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.13428, 0.809, 0.804, 0.806,  0.927/ BF 0.810} : 100%",
       "layout": "IPY_MODEL_7d742e3604cb4e8eb783cb45aeee870b",
       "max": 174,
       "style": "IPY_MODEL_2af8fc86a5f64e71876a0789ce32e184",
       "value": 174
      }
     },
     "546087b1d49346a8a1f0ed6afef1fb16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "5614e8f87a2c4d3f94a1352f8de62094": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "5657752a2f324c1eb41d3f435b0c7cf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "567ca2c6436a407482b0224981a1c96d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "56b327c36bed477682e6bdf9c74cceb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5bac2cb1977744eda283d07d3f9a49f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_70268e1e8c4f4a009bfed18e971d50f0",
       "style": "IPY_MODEL_b90ec11542134681bc6acc828bba79ba",
       "value": " 174/174 [00:18&lt;00:00,  9.53it/s]"
      }
     },
     "61a710f916914b6b8df7bfbae02f5f97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a81313bae19c4577998a610e580190a6",
       "style": "IPY_MODEL_daabd551357048078a487d73f6855027",
       "value": " 174/174 [01:05&lt;00:00,  2.65it/s]"
      }
     },
     "62520786ba34495998782320bf66f8f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "627b5107c1d34e04830c105f72824a95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "65c385ff8f4046b5b7799ceb258389b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.04631, 0.888, 0.950, 0.918,  0.976/ BF 0.918} : 100%",
       "layout": "IPY_MODEL_5614e8f87a2c4d3f94a1352f8de62094",
       "max": 174,
       "style": "IPY_MODEL_0875182a1b4747d2aa00f5d9152b655f",
       "value": 174
      }
     },
     "67a3c39002e54a7eb807216e0e6c7a3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.00765, 0.900, 0.866, 0.883,  0.968/ BF 0.884} : 100%",
       "layout": "IPY_MODEL_71b2aeaa8c4d4d95b8550787ed970651",
       "max": 4353,
       "style": "IPY_MODEL_fdd0f2cb314641b8b9c6d587547751e5",
       "value": 4353
      }
     },
     "6f1feee44a774e3a85e77447f6bd51fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "70268e1e8c4f4a009bfed18e971d50f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "715a822107eb4e5a892ca8c429cb0d09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.05231, 0.872, 0.943, 0.907,  0.972/ BF 0.907} : 100%",
       "layout": "IPY_MODEL_1e2c414a8b3240c3b232f7cb9f135d64",
       "max": 174,
       "style": "IPY_MODEL_352e7c65ac0b487c9b1ceae9dd2cdd30",
       "value": 174
      }
     },
     "71b2aeaa8c4d4d95b8550787ed970651": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "7277f674ec3a4df9b66f0271b2bf5492": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "7338072c8dc44303a7bfcbffae21a9bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "756633856224416b8e9c36c3605422c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "78480c07ab904c448fe5888b3432c839": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.00186, 0.927, 0.906, 0.916,  0.978/ BF 0.916} : 100%",
       "layout": "IPY_MODEL_c2c31132b9f141dd9459992fc7216de3",
       "max": 4353,
       "style": "IPY_MODEL_f66f214dcfa648f4b8fa984dab592392",
       "value": 4353
      }
     },
     "79ace6c1f33d46db921692184459eb28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.09749, 0.763, 0.709, 0.735,  0.888/ BF 0.735} : 100%",
       "layout": "IPY_MODEL_c27779c53e0746d39cf4b3ff5a8c3d77",
       "max": 174,
       "style": "IPY_MODEL_99b77728488d4a4c9a04cce6ae36442c",
       "value": 174
      }
     },
     "7b12270c35bf43dbb5ebeebbdc3768bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cbac94b603364979bd31e85c7e77dbce",
        "IPY_MODEL_ca28202015d44406b662ce463132eaa6"
       ],
       "layout": "IPY_MODEL_9cba73c6a0ef491291287c183ef2d4fd"
      }
     },
     "7d684121338d4cd4a23b542cb79f9e18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7d742e3604cb4e8eb783cb45aeee870b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "7e58ed006a444db083b69075e54b8f35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_715a822107eb4e5a892ca8c429cb0d09",
        "IPY_MODEL_cad9e078f4bc4cc58b1b19805341c202"
       ],
       "layout": "IPY_MODEL_1aabb28858544509b422938b3b06c474"
      }
     },
     "81f2a85f942b428a8cb97f3a4aaa2799": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "82f89ef8714b4505aed02f44de64f605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_34ccbf88aa5542b68da5ff76a5c7c274",
       "style": "IPY_MODEL_40fed54cde3c4054aff1f86e0097a003",
       "value": " 4353/4353 [09:21&lt;00:00,  7.76it/s]"
      }
     },
     "835b4db9434a468facdc052491b44170": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "87965c469b284969a88920553dd1d98e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.00577, 0.902, 0.863, 0.882,  0.967/ BF 0.882} : 100%",
       "layout": "IPY_MODEL_dedfb89e8a5a4193a542d1810469051e",
       "max": 4353,
       "style": "IPY_MODEL_9c0ac6dca7614acca32433dcab0f92f0",
       "value": 4353
      }
     },
     "87c3653b856d4060a9c28a5f5bae96bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c650706bbd74aeda50c9e031c7ca16a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.05223, 0.895, 0.956, 0.925,  0.976/ BF 0.927} : 100%",
       "layout": "IPY_MODEL_8f2b076786ed46188d8eb9368c7ca017",
       "max": 174,
       "style": "IPY_MODEL_d273e9d291c1463a87d1744b9b7375f1",
       "value": 174
      }
     },
     "8dfb4981def74335b56c1cc4ea2645cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "8e20f3719373489e923dd23f58a27231": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "8f2b076786ed46188d8eb9368c7ca017": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "909b06b420f74fbe854670e115d29114": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "94cf63e8807a44788ce6f30041f517d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98de5bd2d62f488683cfede22fbf44a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_65c385ff8f4046b5b7799ceb258389b8",
        "IPY_MODEL_b9f3e5a038f44e59808d72595d4b5a80"
       ],
       "layout": "IPY_MODEL_567ca2c6436a407482b0224981a1c96d"
      }
     },
     "990759c2ffbd433f93934326e545a52e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "999209b5ce9e4445a1c5703544d40a9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "99b77728488d4a4c9a04cce6ae36442c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "9aaca73fc1e244bbbcfd6ec330b25e35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.07817, 0.819, 0.858, 0.838,  0.951/ BF 0.838} : 100%",
       "layout": "IPY_MODEL_18975cb9da8b4a66b26a558ada57eb10",
       "max": 174,
       "style": "IPY_MODEL_7277f674ec3a4df9b66f0271b2bf5492",
       "value": 174
      }
     },
     "9b5507391f684217a8a859ca9eed3e34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3d6dd986de964880925afe9af62dbf28",
       "style": "IPY_MODEL_909b06b420f74fbe854670e115d29114",
       "value": " 174/174 [00:18&lt;00:00,  9.49it/s]"
      }
     },
     "9c0ac6dca7614acca32433dcab0f92f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "9cba73c6a0ef491291287c183ef2d4fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "a60b3bf1a0f0439ca3759ea1d2c045ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "a76ba3aa946c448ab3a044befcd94263": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a7a86f7dc05f47b6a496e8fcb7ef6b3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a81313bae19c4577998a610e580190a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aaf70c721e8e4f2eb73f5577f26a3b3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e72377ff852747b18af3424ad2374088",
       "style": "IPY_MODEL_3a59adf3c26447e89fceaee696ae7fab",
       "value": " 174/174 [00:18&lt;00:00,  9.49it/s]"
      }
     },
     "abf5ba7cbe574e2e8638e531bc7303f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.01887, 0.816, 0.726, 0.769,  0.920/ BF 0.769} : 100%",
       "layout": "IPY_MODEL_c78ec3d359404db1bd1d3692d8aaa433",
       "max": 4353,
       "style": "IPY_MODEL_8dfb4981def74335b56c1cc4ea2645cd",
       "value": 4353
      }
     },
     "b0da8abb43ca48309fbfece666dc75ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "b157317f82b343a3a7f12696b764b88d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2ba6113093174861b6325a0d8c8ffb53",
       "style": "IPY_MODEL_400eeae29a70417189bdb3b861bf275b",
       "value": " 4353/4353 [13:37&lt;00:00,  5.32it/s]"
      }
     },
     "b24bb073ebee4d23842dd0cbbc2e44f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b2dc07ceff4249f1b549dab4864c1b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "b6d3a62e47c24bb5a54198b51f6ad1f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a7a86f7dc05f47b6a496e8fcb7ef6b3a",
       "style": "IPY_MODEL_756633856224416b8e9c36c3605422c7",
       "value": " 174/174 [01:24&lt;00:00,  2.07it/s]"
      }
     },
     "b6dc047654e5402488a8c1c5f5c6709d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "b90ec11542134681bc6acc828bba79ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b9f3e5a038f44e59808d72595d4b5a80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4bdcd0bde26d440e9357fa93c1603392",
       "style": "IPY_MODEL_503ba4e658b140c3acc246c48017a6e5",
       "value": " 174/174 [13:05:57&lt;00:00, 271.02s/it]"
      }
     },
     "bc386895a30844329164a7dbf0783263": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "bce587bed1c74de2a07d75f5ff32e6b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2830f753715b42a5a58bad02c53eaf60",
        "IPY_MODEL_82f89ef8714b4505aed02f44de64f605"
       ],
       "layout": "IPY_MODEL_08211dc7247c4ff5ac7dcdd7aea20e2c"
      }
     },
     "bdd547e134c04deb910d4bba67c985c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "bdf2a6a235574886a49b75a027e57414": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "be6647cb07124cc6a9d3bd26e0d6092b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3e8d5adc640244aa9cba6d0a57a9f742",
       "style": "IPY_MODEL_b24bb073ebee4d23842dd0cbbc2e44f4",
       "value": " 4353/4353 [04:46&lt;00:00, 15.20it/s]"
      }
     },
     "c27779c53e0746d39cf4b3ff5a8c3d77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "c2c31132b9f141dd9459992fc7216de3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "c5c72d85dcd049cc85e503ed5da2e933": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "c68ce0effc1b481a8828b217715cfe89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_87965c469b284969a88920553dd1d98e",
        "IPY_MODEL_f2b1b9dad3f1450a9a31406d24e2c433"
       ],
       "layout": "IPY_MODEL_627b5107c1d34e04830c105f72824a95"
      }
     },
     "c78ec3d359404db1bd1d3692d8aaa433": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "ca28202015d44406b662ce463132eaa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_247aa67b0d524ce591f032e43089dca4",
       "style": "IPY_MODEL_7d684121338d4cd4a23b542cb79f9e18",
       "value": " 174/174 [00:46&lt;00:00,  3.73it/s]"
      }
     },
     "cad9e078f4bc4cc58b1b19805341c202": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_333e1942561641b2acb241acbf0063fe",
       "style": "IPY_MODEL_d28b5dd24e6f4a60b87616ee3de5b207",
       "value": " 174/174 [00:27&lt;00:00,  6.29it/s]"
      }
     },
     "cb4e89c39e5c472b951101fa40c41bc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cbac94b603364979bd31e85c7e77dbce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.05539, 0.852, 0.908, 0.879,  0.967/ BF 0.879} : 100%",
       "layout": "IPY_MODEL_0a236c04424d4beebc8550b66d70a604",
       "max": 174,
       "style": "IPY_MODEL_b2dc07ceff4249f1b549dab4864c1b4e",
       "value": 174
      }
     },
     "cc24e45743f147fcb177e2eb2680e4aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d273e9d291c1463a87d1744b9b7375f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "d28b5dd24e6f4a60b87616ee3de5b207": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d2b371608d444db88dcf65840bfad964": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cb4e89c39e5c472b951101fa40c41bc7",
       "style": "IPY_MODEL_56b327c36bed477682e6bdf9c74cceb2",
       "value": " 4353/4353 [18:43&lt;00:00,  3.87it/s]"
      }
     },
     "d36ec84dc9be4c3e95eef1dda1cf210b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d4054f2608f5456390b3415680bebb87",
        "IPY_MODEL_e94a8671f8d24c499b72c9af20597339"
       ],
       "layout": "IPY_MODEL_8e20f3719373489e923dd23f58a27231"
      }
     },
     "d4054f2608f5456390b3415680bebb87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.05134, 0.882, 0.927, 0.904,  0.973/ BF 0.907} : 100%",
       "layout": "IPY_MODEL_4cc47e2021224d65bead9a91ebab69c3",
       "max": 174,
       "style": "IPY_MODEL_4f8407b099ae4fc7a6368fabe730f51a",
       "value": 174
      }
     },
     "d61840085c7b4761b9b13adfc86210bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d68ae1766f06446699097f571f3f9cae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_523573c6f65a43eea83ff94dcb6ded30",
        "IPY_MODEL_61a710f916914b6b8df7bfbae02f5f97"
       ],
       "layout": "IPY_MODEL_09f4d332b91f46229b81ffd0a64326db"
      }
     },
     "d7cc5c9306ed43f696f31e7d7efc6d9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "d8d161dbe003448bb5131cf37113c74b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_49273e5401a34509914842dfc87c217d",
        "IPY_MODEL_32727aeae87f4dc5b18580c3de79fb30"
       ],
       "layout": "IPY_MODEL_546087b1d49346a8a1f0ed6afef1fb16"
      }
     },
     "daabd551357048078a487d73f6855027": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dc145ac6a4b84a9e9ef5015b301af9d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dedfb89e8a5a4193a542d1810469051e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "e2ee757ff1684f1f9e0a8f62cd89d531": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0ca5c7c74ea0414c94c86945493c81ab",
        "IPY_MODEL_be6647cb07124cc6a9d3bd26e0d6092b"
       ],
       "layout": "IPY_MODEL_5657752a2f324c1eb41d3f435b0c7cf7"
      }
     },
     "e439ca65dee24359a000a505ed41a480": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "e5cabab7f13f42fb81dde667eff08437": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8c650706bbd74aeda50c9e031c7ca16a",
        "IPY_MODEL_4825005b81e049bdb5b5fa385d1f1543"
       ],
       "layout": "IPY_MODEL_07e05f82a76149c6aef1fdb2b608388a"
      }
     },
     "e6b65458345c4387b105fc05d1da0347": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9aaca73fc1e244bbbcfd6ec330b25e35",
        "IPY_MODEL_aaf70c721e8e4f2eb73f5577f26a3b3b"
       ],
       "layout": "IPY_MODEL_2c6247b18d654affb989d2053958ca1d"
      }
     },
     "e72377ff852747b18af3424ad2374088": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e94a8671f8d24c499b72c9af20597339": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39c695f951e140a4bb61f4e503fc35de",
       "style": "IPY_MODEL_334c6b14a9d3477c805707ff58c1a8e6",
       "value": " 174/174 [00:18&lt;00:00,  9.40it/s]"
      }
     },
     "eb7e38089e7b4914913927da6b0847a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "ed9e400772c643aa9f8410064a2b7c28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_87c3653b856d4060a9c28a5f5bae96bb",
       "style": "IPY_MODEL_6f1feee44a774e3a85e77447f6bd51fc",
       "value": " 72/174 [00:20&lt;00:05, 20.16it/s]"
      }
     },
     "ee14c53b32cf4662806cdbf976869636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a76ba3aa946c448ab3a044befcd94263",
       "style": "IPY_MODEL_dc145ac6a4b84a9e9ef5015b301af9d1",
       "value": " 4353/4353 [07:32&lt;00:00,  9.62it/s]"
      }
     },
     "f2b1b9dad3f1450a9a31406d24e2c433": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f4c923d28fff4d88828d37f29bb346f8",
       "style": "IPY_MODEL_d61840085c7b4761b9b13adfc86210bf",
       "value": " 4353/4353 [09:25&lt;00:00,  7.70it/s]"
      }
     },
     "f4758f51c0cc4a4fa8289405657f4498": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f4b040a930b44e699f22be5c05ff6d42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "f4c923d28fff4d88828d37f29bb346f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f66f214dcfa648f4b8fa984dab592392": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "f8e9ec2e9f5d463da62eddad475cabba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "800px"
      }
     },
     "f988f4156b17413290924e4464703cb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_94cf63e8807a44788ce6f30041f517d7",
       "style": "IPY_MODEL_097644bf303f42ba8cb98cbf57eff30e",
       "value": " 4353/4353 [09:17&lt;00:00,  7.81it/s]"
      }
     },
     "fa076cd196b34fdcafcac2d9110ec12e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "It { L 0.06527, 0.862, 0.939, 0.899,  0.970/ BF 0.899} : 100%",
       "layout": "IPY_MODEL_b0da8abb43ca48309fbfece666dc75ee",
       "max": 174,
       "style": "IPY_MODEL_b6dc047654e5402488a8c1c5f5c6709d",
       "value": 174
      }
     },
     "fb2ffabe3d2e4c0cb5e8ce128d3cbbc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "fdd0f2cb314641b8b9c6d587547751e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
